Accelerated Proximal Gradient Methods for

Nonconvex Programming

Huan Li

Zhouchen Lin (cid:66)

Key Lab. of Machine Perception (MOE), School of EECS, Peking University, P. R. China

Cooperative Medianet Innovation Center, Shanghai Jiaotong University, P. R. China

lihuanss@pku.edu.cn

zlin@pku.edu.cn

Abstract

Nonconvex and nonsmooth problems have recently received considerable atten-
tion in signal/image processing, statistics and machine learning. However, solv-
ing the nonconvex and nonsmooth optimization problems remains a big challenge.
Accelerated proximal gradient (APG) is an excellent method for convex program-
ming. However, it is still unknown whether the usual APG can ensure the con-
vergence to a critical point in nonconvex programming. In this paper, we extend
APG for general nonconvex and nonsmooth programs by introducing a monitor
that satisﬁes the sufﬁcient descent property. Accordingly, we propose a monotone
APG and a nonmonotone APG. The latter waives the requirement on monotonic
reduction of the objective function and needs less computation in each iteration.
To the best of our knowledge, we are the ﬁrst to provide APG-type algorithms
for general nonconvex and nonsmooth problems ensuring that every accumulation

point is a critical point, and the convergence rates remain O(cid:0) 1

(cid:1) when the prob-

lems are convex, in which k is the number of iterations. Numerical results testify
to the advantage of our algorithms in speed.

k2

1

Introduction

In recent years, sparse and low rank learning has been a hot research topic and leads to a wide
variety of applications in signal/image processing, statistics and machine learning.
l1-norm and
nuclear norm, as the continuous and convex surrogates of l0-norm and rank, respectively, have been
used extensively in the literature. See e.g., the recent collections [1]. Although l1-norm and nuclear
norm have achieved great success, in many cases they are suboptimal as they can promote sparsity
and low-rankness only under very limited conditions [2, 3]. To address this issue, many nonconvex
regularizers have been proposed, such as lp-norm [4], Capped-l1 penalty [3], Log-Sum Penalty [2],
Minimax Concave Penalty [5], Geman Penalty [6], Smoothly Clipped Absolute Deviation [7] and
Schatten-p norm [8]. This trend motivates a revived interest in the analysis and design of algorithms
for solving nonconvex and nonsmooth problems, which can be formulated as

min
x∈Rn

F (x) = f (x) + g(x),

(1)

where f is differentiable (it can be nonconvex) and g can be both nonconvex and nonsmooth.
Accelerated gradient methods have been at the heart of convex optimization research. In a series of
celebrated works [9, 10, 11, 12, 13, 14], several accelerated gradient methods are proposed for prob-
lem (1) with convex f and g. In these methods, k iterations are sufﬁcient to ﬁnd a solution within

(cid:1) error from the optimal objective value. Recently, Ghadimi and Lan [15] presented a uniﬁed

O(cid:0) 1

treatment of accelerated gradient method (UAG) for convex, nonconvex and stochastic optimiza-

k2

1

Table 1: Comparisons of GD (General Descent Method), iPiano, GIST, GDPA, IR, IFB, APG, UAG
and our method for problem (1). The measurements include the assumption, whether the methods
accelerate for convex programs (CP) and converge for nonconvex programs (NCP).

Method name
GD [16, 17]
iPiano [18]
GIST [19]
GDPA [20]
IR [8, 21]
IFB [22]

APG [12, 13]

UAG [15]

Ours

Assumption
f + g: KL

nonconvex f, convex g

nonconvex f, g = g1 − g2, g1, g2 convex
nonconvex f, g = g1 − g2, g1, g2 convex

special f and g

nonconvex f, nonconvex g

convex f, convex g

nonconvex f, convex g

nonconvex f, nonconvex g

Accelerate (CP)

converge (NCP)

No
No
No
No
No
No
Yes
Yes
Yes

Yes
Yes
Yes
Yes
Yes
Yes

Yes
Yes

Unclear

k2

convex g and accelerates with an O(cid:0) 1

(cid:1) convergence rate in convex programming for problem (1).

tion. They proved that their algorithm converges1 in nonconvex programming with nonconvex f but

Convergence rate about the gradient mapping is also analyzed in [15].
Attouch et al. [16] proposed a uniﬁed framework to prove the convergence of a general class of
descent methods using the Kurdyka-Łojasiewicz (KL) inequality for problem (1) and Frankel et
al. [17] studied the convergence rates of general descent methods under the assumption that the
desingularising function ϕ in KL property has the form of C
θ tθ. A typical example in their frame-
work is the proximal gradient method. However, there is no literature showing that there exists an
accelerated gradient method satisfying the conditions in their framework.
Other typical methods for problem (1) includes Inertial Forward-Backward (IFB) [22], iPiano [18],
General Iterative Shrinkage and Thresholding (GIST) [19], Gradient Descent with Proximal Aver-
age(GDPA) [20] and Iteratively Reweighted Algorithms (IR) [8, 21]. Table 1 demonstrates that the
existing methods are not ideal. GD and IFB cannot accelerate the convergence for convex programs.
GIST and GDPA require that g should be explicitly written as a difference of two convex functions.
iPiano demands the convexity of g and IR is suitable for some special cases of problem (1). APG
can accelerate the convergence for convex programs, however, it is unclear whether APG can con-
verge to critical points for nonconvex programs. UAG can ensure the convergence for nonconvex
programming, however, it requires g to be convex. This restricts the applications of UAG to solving
nonconvexly regularized problems, such as sparse and low rank learning. To the best of our knowl-
edge, extending the accelerated gradient method for general nonconvex and nonsmooth programs

(cid:1) convergence rate in the convex case remains an open problem.

while keeping the O(cid:0) 1

k2

In this paper we aim to extend Beck and Teboulle’s APG [12, 13] to solve general nonconvex and
nonsmooth problem (1). APG ﬁrst extrapolates a point yk by combining the current point and
the previous point, then solves a proximal mapping problem. When extending APG to nonconvex
programs the chief difﬁculty lies in the extrapolated point yk. We have little restriction on F (yk)
when the convexity is absent. In fact, F (yk) can be arbitrarily larger than F (xk) when yk is a bad
extrapolation, especially when F is oscillatory. When xk+1 is computed by a proximal mapping at
a bad yk, F (xk+1) may also be arbitrarily larger than F (xk). Beck and Teboulle’s monotone APG
[12] ensures F (xk+1) ≤ F (xk). However, this is not enough to ensure the convergence to critical
points. To address this issue, we introduce a monitor satisfying the sufﬁcient descent property to
prevent a bad extrapolation of yk and then correct it by this monitor. In summary, our contributions
include:

1. We propose APG-type algorithms for general nonconvex and nonsmooth programs (1). We
ﬁrst extend Beck and Teboulle’s monotone APG [12] by replacing their descent condition
with sufﬁcient descent condition. This critical change ensures that every accumulation point
is a critical point. Our monotone APG satisﬁes some modiﬁed conditions for the framework
of [16, 17] and thus stronger results on convergence rate can be obtained under the KL

1Except for the work under the KL assumption, convergence for nonconvex problems in this paper and the

references of this paper means that every accumulation point is a critical point.

2

assumption. Then we propose a nonmonotone APG, which allows for larger stepsizes
when line search is used and reduces the average number of proximal mappings in each
iteration. Thus it can further speed up the convergence in practice.

2. For our APGs, the convergence rates maintain O(cid:0) 1

(cid:1) when the problems are convex. This

result is of great signiﬁcance when the objective function is locally convex in the neighbor-
hoods of local minimizers even if it is globally nonconvex.

k2

2 Preliminaries

2.1 Basic Assumptions
Note that a function g : Rn → (−∞, +∞] is said to be proper if dom g (cid:54)= ∅, where dom g =
{x ∈ R : g(x) < +∞}. g is lower semicontinuous at point x0 if lim inf x→x0 g(x) ≥ g(x0). In
problem (1), we assume that f is a proper function with Lipschitz continuous gradients and g is
proper and lower semicontinuous. We assume that F (x) is coercive, i.e., F is bounded from below
and F (x) → ∞ when (cid:107)x(cid:107) → ∞, where (cid:107) · (cid:107) is the l2-norm.

2.2 KL Inequality
Deﬁnition 1. [23] A function f : Rn → (−∞, +∞] is said to have the KL property at u ∈
dom∂f := {x ∈ Rn : ∂f (u) (cid:54)= ∅} if there exists η ∈ (0, +∞], a neighborhood U of u and a

function ϕ ∈ Φη, such that for all u ∈ U(cid:84){u ∈ Rn : f (u) < f (u) < f (u) + η}, the following

inequality holds

(2)
where Φη stands for a class of function ϕ : [0, η) → R+ satisfying: (1) ϕ is concave and C 1 on
(0, η); (2) ϕ is continuous at 0, ϕ(0) = 0; and (3) ϕ(cid:48)(x) > 0, ∀x ∈ (0, η).

ϕ(cid:48)(f (u) − f (u))dist(0, ∂f (u)) > 1,

All semi-algebraic functions and subanalytic functions satisfy the KL property. Specially, the desin-
gularising function ϕ(t) of semi-algebraic functions can be chosen to be the form of C
θ tθ with
θ ∈ (0, 1]. Typical semi-algebraic functions include real polynomial functions, (cid:107)x(cid:107)p with p ≥ 0,
rank(X), the indicator function of PSD cone, Stiefel manifolds and constant rank matrices [23].

2.3 Review of APG in the Convex Case

We ﬁrst review APG in the convex case. Bech and Teboulle [13] extend Nesterov’s accelerated
gradient method to the nonsmooth case. It is named the Accelerated Proximal Gradient method and
consists of the following steps:

tk−1 − 1

(xk − xk−1),
yk = xk +
xk+1 = proxαkg(yk − αk∇f (yk)),

(cid:112)4(tk)2 + 1 + 1

tk

(5)
2α(cid:107)x − u(cid:107)2. APG is not
where the proximal mapping is deﬁned as proxαg(x) = argminu g(u) + 1
a monotone algorithm, which means that F (xk+1) may not be smaller than F (xk). So Beck and
Teboulle [12] further proposed a monotone APG, which consists of the following steps:

tk+1 =

2

,

(3)

(4)

(6)

(7)

(8)

(9)

(zk − xk) +

yk = xk +
tk
zk+1 = proxαkg(yk − αk∇f (yk)),

tk−1
tk

tk−1 − 1

(xk − xk−1),

(cid:112)4(tk)2 + 1 + 1
(cid:26) zk+1,

2

,

xk,

tk+1 =

xk+1 =

if F (zk+1) ≤ F (xk),
otherwise.

3

3 APGs for Nonconvex Programs

We establish the convergence in the nonconvex case and the O(cid:0) 1

(cid:1) convergence rate in the convex

k2

In this section, we propose two APG-type algorithms for general nonconvex nonsmooth problems.

case. When the KL property is satisﬁed we also provide stronger results on convergence rate.

3.1 Monotone APG

We give two reasons that result in the difﬁculty of convergence analysis on the usual APG [12, 13]
for nonconvex programs: (1) yk may be a bad extrapolation, (2) in [12] only descent property,
F (xk+1) ≤ F (xk), is ensured. To address these issues, we need to monitor and correct yk when
it has the potential to fail, and the monitor should enjoy the property of sufﬁcient descent which is
critical to ensure the convergence to a critical point. As is known, proximal gradient methods can
make sure sufﬁcient descent [16] (cf. (15)). So we use a proximal gradient step as the monitor. More
specially, our algorithm consists of the following steps:

(10)

(11)
(12)

(13)

(14)

tk−1 − 1

(xk − xk−1),

tk−1
tk

(zk − xk) +

yk = xk +
tk
zk+1 = proxαyg(yk − αy∇f (yk)),
vk+1 = proxαxg(xk − αx∇f (xk)),

(cid:112)4(tk)2 + 1 + 1
(cid:26) zk+1,

2

,

tk+1 =

xk+1 =

vk+1, otherwise.

if F (zk+1) ≤ F (vk+1),

where αy and αx can be ﬁxed constants satisfying αy < 1
L, or dynamically computed
by backtracking line search initialized by Barzilai-Borwein rule2. L is the Lipschitz constant of ∇f.
Our algorithm is an extension of Beck and Teboulle’s monotone APG [12]. The difference lies in
the extra v, as the role of monitor, and the correction step of x-update. In (9) F (zk+1) is compared
with F (xk), while in (14) F (zk+1) is compared with F (vk+1). A further difference is that Beck
and Teboulle’s algorithm only ensures descent while our algorithm makes sure sufﬁcient descent,
which means

L and αx < 1

F (xk+1) ≤ F (xk) − δ(cid:107)vk+1 − xk(cid:107)2,

(15)
where δ > 0 is a small constant. It is not difﬁcult to understand that only the descent property cannot
ensure the convergence to a critical point in nonconvex programming. We present our convergence
result in the following theorem3.
Theorem 1. Let f be a proper function with Lipschitz continuous gradients and g be proper and
lower semicontinuous. For nonconvex f and nonconvex nonsmooth g, assume that F (x) is coercive.
Then {xk} and {vk} generated by (10)-(14) are bounded. Let x∗ be any accumulation point of
{xk}, we have 0 ∈ ∂F (x∗), i.e., x∗ is a critical point.
A remarkable aspect of our algorithm is that although we have made some modiﬁcations on Beck

(cid:1) convergence rate in the convex case still holds. Similar to

and Teboulle’s algorithm, the O(cid:0) 1

Theorem 5.1 in [12], we have the following theorem on the accelerated convergence in the convex
case:
Theorem 2. For convex f and g, assume that ∇f is Lipschitz continuous, let x∗ be any global
optimum, then {xk} generated by (10)-(14) satisﬁes
2

k2

F (xN +1) − F (x∗) ≤

2 means that APG can ensure to have an O(cid:0) 1

αy(N + 1)2(cid:107)x0 − x∗(cid:107)2,
(cid:1) convergence rate when approaching to a local

(16)

k2

When the objective function is locally convex in the neighborhood of local minimizers, Theorem

minimizer, thus accelerating the convergence.
For better reference, we summarize the proposed monotone APG algorithm in Algorithm 1.

2For the detail of line search with Barzilai-Borwein initializtion please see Supplementary Materials.
3The proofs in this paper can be found in Supplementary Materials.

4

Algorithm 1 Monotone APG

Initialize z1 = x1 = x0, t1 = 1, t0 = 0, αy < 1
for k = 1, 2, 3,··· do

L, αx < 1
L.

update yk, zk+1, vk+1, tk+1 and xk+1 by (10)-(14).

end for

3.2 Convergence Rate under the KL Assumption

The KL property is a powerful tool and is studied by [16], [17] and [23] for a class of general
descent methods. The usual APG in [12, 13] does not satisfy the sufﬁcient descent property, which
is crucial to use the KL property, and thus has no conclusions under the KL assumption. On the
other hand, due to the intermediate variables yk, vk and zk, our algorithm is more complex than
the general descent methods and also does not satisfy the conditions therein. However, due to the
monitor-corrector step (12) and (14), some modiﬁed conditions4 can be satisﬁed and we can still
get some exciting results under the KL assumption. With the same framework of [17], we have the
following theorem.
Theorem 3. Let f be a proper function with Lipschitz continuous gradients and g be proper and
lower semicontinuous. For nonconvex f and nonconvex nonsmooth g, assume that F (x) is coercive.
If we further assume that f and g satisfy the KL property and the desingularising function has the
form of ϕ(t) = C

θ tθ for some C > 0, θ ∈ (0, 1], then

1. If θ = 1, then there exists k1 such that F (xk) = F ∗ for all k > k1 and the algorithm

terminates in ﬁnite steps.

2. If θ ∈ [ 1

2 , 1), then there exists k2 such that for all k > k2,

(cid:18) d1C 2

(cid:19)k−k2

1 + d1C 2

F (xk) − F ∗ ≤

rk2.

(17)

3. If θ ∈ (0, 1

2 ), then there exists k3 such that for all k > k3,

(cid:19) 1

1−2θ

F (xk) − F ∗ ≤

C

(18)
where F ∗ is the same function value at all the accumulation points of {xk}, rk = F (vk)−
F ∗, d1 =

(k − k3)d2(1 − 2θ)

(cid:110) 1

and d2 = min

(cid:16) 1

(cid:16) 1

2θ−2 − 1
2θ−1

2

(cid:17)2

,

(cid:16)

(cid:111)

(cid:17)

r2θ−1

0

+ L

/

αx

2αx

2d1C , C
1−2θ

− L

2

(cid:18)
(cid:17)

When F (x) is a semi-algebraic function, the desingularising function ϕ(t) can be chosen to be the
θ tθ with θ ∈ (0, 1] [23]. In this case, as shown in Theorem 3, our algorithm converges in
form of C
ﬁnite iterations when θ = 1, converges with a linear rate when θ ∈ [ 1
2 , 1) and a sublinear rate (at
2 ) for the gap F (xk) − F ∗. This is the same as the results mentioned in
k )) when θ ∈ (0, 1
least O( 1
[17], although our algorithm does not satisfy the conditions therein.

3.3 Nonmonotone APG

Algorithm 1 is a monotone algorithm. When the problem is ill-conditioned, a monotone algorithm
has to creep along the bottom of a narrow curved valley so that the objective function value does not
increase, resulting in short stepsizes or even zigzagging and hence slow convergence [24]. Removing
the requirement on monotonicity can improve convergence speed because larger stepsizes can be
adopted when line search is used.
On the other hand, in Algorithm 1 we need to compute zk+1 and vk+1 in each iteration and use
vk+1 to monitor and correct zk+1. This is a conservative strategy. In fact, we can accept zk+1 as
xk+1 directly if it satisﬁes some criterion showing that yk is a good extrapolation. Then vk+1 is
computed only when this criterion is not met. Thus, we can reduce the average number of proximal

4For the details of difference please see Supplementary Materials.

5

mappings, accordingly the computation cost, in each iteration. So in this subsection we propose a
nonmonotone APG to speed up convergence.
In monotone APG, (15) is ensured. In nonmonotone APG, we allow xk+1 to make a larger objec-
tive function value than F (xk). Speciﬁcally, we allow xk+1 to yield an objective function value
smaller than ck, a relaxation of F (xk). ck should not be too far from F (xk). So the average of
F (xk), F (xk−1),··· , F (x1) is a good choice. Thus we follow [24] to deﬁne ck as a convex com-
bination of F (xk), F (xk−1),··· , F (x1) with exponentially decreasing weights:

ck =

,

(19)

where η ∈ [0, 1) controls the degree of nonmonotonicity. In practice ck can be efﬁciently computed
by the following recursion:

(cid:80)k
(cid:80)k
j=1 ηk−jF (xj)

j=1 ηk−j

qk+1 = ηqk + 1,

ck+1 =

ηqkck + F (xk+1)

qk+1

,

(20)

(21)

where q1 = 1 and c1 = F (x1).
According to (14), we can split (15) into two parts by the different choices of xk+1. Accordingly, in
nonmonotone APG we consider the following two conditions to replace (15):

F (zk+1) ≤ ck − δ(cid:107)zk+1 − yk(cid:107)2,
F (vk+1) ≤ ck − δ(cid:107)vk+1 − xk(cid:107)2.

(22)
(23)
We choose (22) as the criteria mentioned before. When (22) holds, we deem that yk is a good
extrapolation and accept zk+1 directly. Then we do not compute vk+1 in this case. However, (22)
does not hold all the time. When it fails, we deem that yk may not be a good extrapolation. In this
case, we compute vk+1 by (12) satisfying (23), and then monitor and correct zk+1 by (14). (23) is
ensured when αx ≤ 1/L. When backtracking line search is used, such vk+1 that satisﬁes (23) can
be found in ﬁnite steps5.
Combing (20), (21), (22) and xk+1 = zk+1 we have

ck+1 ≤ ck − δ(cid:107)xk+1 − yk(cid:107)2

.

qk+1

(24)

(25)

Similarly, replacing (22) and xk+1 = zk+1 by (23) and xk+1 = vk+1, respectively, we have

ck+1 ≤ ck − δ(cid:107)xk+1 − xk(cid:107)2

.

qk+1

This means that we replace the sufﬁcient descent condition of F (xk) in (15) by the sufﬁcient descent
of ck.
We summarize the nonmonotone APG in Algorithm 26. Similar to monotone APG, nonmonotone

APG also enjoys the convergence property in the nonconvex case and the O(cid:0) 1

in the convex case. We present our convergence result in Theorem 4. Theorem 2 still holds for
Algorithm 2 with no modiﬁcation. So we omit it here.
Deﬁne Ω1 = {k1, k2,··· , kj,···} and Ω2 = {m1, m2,··· , mj,···}, such that in Algorithm 2,
(22) holds and xk+1 = zk+1 is executed for all k = kj ∈ Ω1. For all k = mj ∈ Ω2, (22) does
not hold and (14) is executed. Then we have Ω1
following theorem holds.
Theorem 4. Let f be a proper function with Lipschitz continuous gradients and g be proper and
lower semicontinuous. For nonconvex f and nonconvex nonsmooth g, assume that F (x) is coercive.
Then {xk}, {vk} and {ykj} where kj ∈ Ω1 generated by Algorithm 2 are bounded, and

(cid:84) Ω2 = ∅, Ω1

(cid:1) convergence rate
(cid:83) Ω2 = {1, 2, 3,··· ,} and the

k2

1. if Ω1 or Ω2 is ﬁnite, then for any accumulation point {x∗} of {xk}, we have 0 ∈ ∂F (x∗).

5See Lemma 2 in Supplementary Materials.
6Please see Supplementary Materials for nonmonotone APG with line search.

6

Algorithm 2 Nonmonotone APG

1

(xk − xk−1),

Initialize z1 = x1 = x0, t1 = 1, t0 = 0, η ∈ [0, 1), δ > 0, c1 = F (x1), q1 = 1, αx < 1
L.
for k = 1, 2, 3,··· do
(zk − xk) + tk−1−1
yk = xk + tk−1
zk+1 = proxαyg(yk − αy∇f (yk))
tk
if F (zk+1) ≤ ck − δ(cid:107)zk+1 − yk(cid:107)2 then
xk+1 = zk+1.
else
vk+1 = proxαxg(xk − αx∇f (xk)),
xk+1 =
√

if F (zk+1) ≤ F (vk+1),

(cid:26) zk+1,

vk+1, otherwise.

tk

L , αy <

4(tk)2+1+1

end if
tk+1 =
qk+1 = ηqk + 1,
ck+1 = ηqkck+F (xk+1)

,

2

qk+1

.

end for

2. if Ω1 and Ω2 are both inﬁnite, then for any accumulation point x∗ of {xkj +1}, y∗ of {ykj}
where kj ∈ Ω1 and any accumulation point v∗ of {vmj +1}, x∗ of {xmj} where mj ∈ Ω2,
we have 0 ∈ ∂F (x∗), 0 ∈ ∂F (y∗) and 0 ∈ ∂F (v∗).

4 Numerical Results

In this section, we test the performance of our algorithm on the problem of Sparse Logistic Re-
gression (LR)7.Sparse LR is an attractive extension to LR as it can reduce overﬁtting and perform
feature selection simultaneously. Sparse LR is widely used in areas such as bioinformatics [25] and
text categorization [26]. In this subsection, we follow Gong et al. [19] to consider Sparse LR with a
nonconvex regularizer:

n(cid:88)

i=1

min

w

1
n

log(1 + exp(−yixT

i w)) + r(w).

We choose r(w) as the capped l1 penalty [3], deﬁned as
min(|wi|, θ),

r(w) = λ

d(cid:88)

θ > 0.

(26)

(27)

i=1

We compare monotone APG (mAPG) and nonmonotone APG (nmAPG) with monotone GIST8
(mGIST), nonmonotone GIST (nmGIST) [19] and IFB [22]. We test the performance on the real-sim
data set9, which contains 72309 samples of 20958 dimensions. We follow [19] to set λ = 0.0001,
θ = 0.1λ and the starting point as zero vectors. In nmAPG we set η = 0.8. In IFB the inertial
parameter β is set at 0.01 and the Lipschitz constant is computed by backtracking. To make a
fair comparison, we ﬁrst run mGIST. The algorithm is terminated when the relative change of two
consecutive objective function values is less than 10−5 or the number of iterations exceeds 1000.
This termination condition is the same as in [19]. Then we run nmGIST, mAPG, nmAPG and
IFB. These four algorithms are terminated when they achieve an equal or smaller objective function
value than that by mGIST or the number of iterations exceeds 1000. We randomly choose 90% of
the data as training data and the rest as test data. The experiment result is averaged over 10 runs. All
algorithms are run on Matlab 2011a and Windows 7 with an Intel Core i3 2.53 GHz CPU and 4GB
memory. The result is reported in Table 2. We also plot the curves of objective function values vs.
iteration number and CPU time in Figure 1.

7For the sake of space limitation we leave another experiment, Sparse PCA, in Supplementary Materials.
8http://www.public.asu.edu/ yje02/Software/GIST
9http://www.csie.ntu.tw/cjlin/libsvmtools/datasets

7

Table 2: Comparisons of APG, GIST and IFB on the sparse logistic regression problem. The quan-
tities include number of iterations, averaged number of line searches in each iteration, computing
time (in seconds) and test error. They are averaged over 10 runs.
Time
300.42
222.22
215.82
133.23
42.99

test error
2.94%
2.94%
2.96%
2.93%
2.97%

#Iter.
994
806
635
175
146

Method
mGIST
nmGIST

2.19
1.69
2.59
2.99
1.01

#Line search

IFB

mAPG
nmAPG

We have the following observations: (1) APG-type methods need much fewer iterations and less
computing time than GIST and IFB to reach the same (or smaller) objective function values. As
GIST is indeed a Proximal Gradient method (PG) and IFB is an extension of PG, this veriﬁes that
APG can indeed accelerate the convergence in practice. (2) nmAPG is faster than mAPG. We give
two reasons: nmAPG avoids the computation of vk in most of the time and reduces the number
of line searches in each iteration. We mention that in mAPG line search is performed in both (11)
and (12), while in nmAPG only the computation of zk+1 needs line search in every iteration. vk+1
is computed only when necessary. We note that the average number of line searches in nmAPG is
nearly one. This means that (22) holds in most of the time. So we can trust that zk can work well in
most of the time and only in a few times vk is computed to correct zk and yk. On the other hand,
nonmonotonicity allows for larger stepsizes, which results in fewer line searches.

(a) Objective function value v.s. iteration

(b) Objective function value v.s. time

Figure 1: Compare the objective function value produced by APG, GIST and IFB.

5 Conclusions

In this paper, we propose two APG-type algorithms for efﬁciently solving general nonconvex non-
smooth problems, which are abundant in machine learning. We provide a detailed convergence
analysis, showing that every accumulation point is a critical point for general nonconvex nonsmooth

programs and the convergence rate is maintained at O(cid:0) 1

(cid:1) for convex programs. Nonmonotone

APG allows for larger stepsizes and needs less computation cost in each iteration and thus is faster
than monotone APG in practice. Numerical experiments testify to the advantage of the two algo-
rithms.

k2

Acknowledgments

Zhouchen Lin is supported by National Basic Research Program of China (973 Program) (grant no.
2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61272341 and
61231002), and Microsoft Research Asia Collaborative Research Program. He is the corresponding
author.

8

02004006008001000−2.6−2.4−2.2−2−1.8−1.6−1.4−1.2−1−0.8IterationFunction Value  mGISTnmGISTIFBmAPGnmAPG050100150200250300−2.6−2.4−2.2−2−1.8−1.6−1.4−1.2−1−0.8CPU TimeFunction Value  mGISTnmGISTIFBmAPGnmAPGReferences
[1] F. Yun, editor. Low-rank and sparse modeling for visual analysis. Springer, 2014. 1
[2] E.J. Candes, M.B. Wakin, and S.P. Boyd. Enhancing sparsity by reweighted l1 minimization. Journal of

Fourier Analysis and Applications, 14(5):877–905, 2008. 1

[3] T. Zhang. Analysis of multi-stage convex relaxation for sparse regularization. The Journal of Machine

Learning Rearch, 11:1081–1107, 2010. 1, 7

[4] S. Foucart and M.J. Lai. Sparsest solutions of underdeterminied linear systems via lq minimization for

0 < q ≤ 1. Applied and Computational Harmonic Analysis, 26(3):395–407, 2009. 1

[5] C.H. Zhang. Nearly unbiased variable selection under minimax concave penalty. The Annals of Statistics,

38(2):894–942, 2010. 1

[6] D. Geman and C. Yang. Nonlinear image recovery with half-quadratic regularization. IEEE Transactions

on Image Processing, 4(7):932–946, 1995. 1

[7] J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal

of the American Statistical Association, 96(456):1348–1360, 2001. 1

[8] K. Mohan and M. Fazel. Iterative reweighted algorithms for matrix rank minimization. The Journal of

Machine Learning Research, 13(1):3441–3473, 2012. 1, 2

[9] Y.E. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence

O(1/k2). Soviet Mathematics Doklady, 27(2):372–376, 1983. 1

[10] Y.E. Nesterov. Smooth minimization of nonsmooth functions. Mathematical programming, 103(1):127–

152, 2005. 1

[11] Y.E. Nesterov. Gradient methods for minimizing composite objective functions. Technical report, Center

for Operations Research and Econometrics(CORE), Catholie University of Louvain, 2007. 1

[12] A. Beck and M. Teboulle. Fast gradient-based algorithms for constrained total variation image denoising
and deblurring problems. IEEE Transactions on Image Processing, 18(11):2419–2434, 2009. 1, 2, 3, 4, 5
[13] A. Beck and M. Teboulle. A fast iterative shrinkage thresholding algorithm for linear inverse problems.

SIAM J. Imaging Sciences, 2(1):183–202, 2009. 1, 2, 3, 4, 5

[14] P. Tseng. On accelerated proximal gradient methods for convex-concave optimization. Technical report,

University of Washington, Seattle, 2008. 1

[15] S. Ghadimi and G. Lan. Accelerated gradient methods for nonconvex nonlinear and stochastic program-

ming. arXiv preprint arXiv:1310.3787, 2013. 1, 2

[16] H. Attouch, J. Bolte, and B.F. Svaier. Convergence of descent methods for semi-algebraic and tame prob-
lems: proximal algorithms, forward-backward splitting, and regularized Gauss-Seidel methods. Mathe-
matical Programming, 137:91–129, 2013. 2, 4, 5

[17] P. Frankel, G. Garrigos, and J. Peypouquet. Splitting methods with variable metric for Kurdyka-
Łojasiewicz functions and general convergence rates. Journal of Optimization Theory and Applications,
165:874–900, 2014. 2, 5

[18] P. Ochs, Y. Chen, T. Brox, and T. Pock. IPiano: Inertial proximal algorithms for nonconvex optimization.

SIAM J. Image Sciences, 7(2):1388–1419, 2014. 2

[19] P. Gong, C. Zhang, Z. Lu, J. Huang, and J. Ye. A general iterative shrinkage and thresholding algorithm

for nonconvex regularized optimization problems. In ICML, pages 37–45, 2013. 2, 7

[20] W. Zhong and J. Kwok. Gradient descent with proximal average for nonconvex and composite regular-

ization. In AAAI, 2014. 2

[21] P. Ochs, A. Dosovitskiy, T. Brox, and T. Pock. On iteratively reweighted algorithms for non-smooth

non-convex optimization in computer vision. SIAM J. Imaging Sciences, 2014. 2

[22] R.L. Bot, E.R. Csetnek, and S. L´aszl´o. An inertial forward-backward algorithm for the minimization of

the sum of two nonconvex functions. Preprint, 2014. 2, 7

[23] J. Bolte, S. Sabach, and M. Teboulle. Proximal alternating linearized minimization for nonconvex and

nonsmooth problems. Mathematical Programming, 146(1-2):459–494, 2014. 3, 5

[24] H. Zhang and W.W. Hager. A nonmonotone line search technique and its application to unconstrained

optimization. SIAM J. Optimization, 14:1043–1056, 2004. 5, 6

[25] S.K. Shevade and S.S. Keerthi. A simple and efﬁcient algorithm for gene selection using sparse logistic

regression. Bioinformatics, 19(17):2246–2253, 2003. 7

[26] A. Genkin, D.D. Lewis, and D. Madigan. Large-scale bayesian logistic regression for text categorization.

Technometrics, 49(14):291–304, 2007. 7

9

