Convergence Analysis of Prediction Markets via

Randomized Subspace Descent

Rafael Frongillo

Department of Computer Science
University of Colorado, Boulder

raf@colorado.edu

Mark D. Reid

Research School of Computer Science

The Australian National University & NICTA

mark.reid@anu.edu.au

Abstract

Prediction markets are economic mechanisms for aggregating information about
future events through sequential interactions with traders. The pricing mecha-
nisms in these markets are known to be related to optimization algorithms in ma-
chine learning and through these connections we have some understanding of how
equilibrium market prices relate to the beliefs of the traders in a market. However,
little is known about rates and guarantees for the convergence of these sequential
mechanisms, and two recent papers cite this as an important open question.
In this paper we show how some previously studied prediction market trading
models can be understood as a natural generalization of randomized coordinate
descent which we call randomized subspace descent (RSD). We establish con-
vergence rates for RSD and leverage them to prove rates for the two prediction
market models above, answering the open questions. Our results extend beyond
standard centralized markets to arbitrary trade networks.

1

Introduction

In recent years, there has been an increasing appreciation of the shared mathematical foundations
between prediction markets and a variety of techniques in machine learning. Prediction markets
consist of agents who trade securities that pay out depending on the outcome of some uncertain,
future event. As trading takes place, the prices of these securities reﬂect an aggregation of the
beliefs the traders have about the future event. A popular class of mechanisms for updating these
prices as trading occurs has been shown to be closely related to techniques from online learning [7,
1, 21], convex optimization [10, 19, 13], probabilistic aggregation [24, 14], and crowdsourcing [3].
Building these connections serve several purposes, however one important line of research has been
to use insights from machine learning to better understand how to interpret prices in a prediction
market as aggregations of trader beliefs, and moreover, how the market together with the traders can
be viewed as something akin to a distributed machine learning algorithm [24].
The analysis in this paper was motivated in part by two pieces of work that considered the equilib-
ria of prediction markets with speciﬁc models of trader behavior: traders as risk minimizers [13];
and traders who maximize expected exponential utility using beliefs from exponential families [2].
In both cases, the focus was on understanding the properties of the market at convergence, and
questions concerning whether and how convergence happened were left as future work. In [2], the
authors note that “we have not considered the dynamics by which such an equilibrium would be
reached, nor the rate of convergence etc., yet we think such questions provide fruitful directions
for future research.” In [13], “One area of future work would be conducting a detailed analysis of
this framework using the tools of convex optimisation. A particularly interesting topic is to ﬁnd the
conditions under which the market will converge.”

1

The main contribution of this paper is to answer these questions of convergence. We do so by ﬁrst
proposing a new and very general model of trading networks and dynamics (§3) that subsumes the
models used in [2] and [13] and provide a key structural result for what we call efﬁcient trades in
these networks (Theorem 2). As an aside, this structural result provides an immediate generalization
of an existing aggregation result in [2] to trade networks of “compatible” agents (Theorem 8). In
§4, we argue that efﬁcient trades in our networks model can be viewed as steps of what we call
Random Subspace Descent (RSD) algorithm (Algorithm 1). This novel generalization of coordinate
descent allows an objective to be minimized by taking steps along afﬁnely constrained subspaces,
and maybe be of independent interest beyond prediction market analysis. We provide a convergence
analysis of RSD under two sets of regularity constraints (Theorems 3 & 9) and show how these can
be used to derive (slow & fast) convergence rates in trade networks (Theorems 4 & 5).
Before introducing our general trading networks and convergence rate results, we ﬁrst introduce the
now standard presentation of potential-based prediction markets [1] and the recent variant in which
all agents determine their trades using risk measures [13]. We will then state informal versions of
our main results so as to highlight how we address issues of convergence in existing frameworks.

2 Background and Informal Results

total of r · φ(ω) =(cid:80)k

Prediction markets are mechanisms for eliciting and aggregating distributed information or beliefs
about uncertain future events. The set of events or outcomes under consideration in the market will
be denoted Ω and may be ﬁnite or inﬁnite. For example, each outcome ω ∈ Ω might represent
a certain presidential candidate winning an election, the location of a missing submarine, or an
unknown label for an item in a data set. Following [1], the goods that are traded in a prediction
market are k outcome-dependent securities {φ(·)i}k
i=1 that pay φ(ω)i dollars should the outcome
ω ∈ Ω occur. We denote the set of distributions over Ω by ∆Ω and note, for any p ∈ ∆Ω, that the
expected pay off for the securities under p is Eω∼p [φ(ω)] and the set of all expected pay offs is just
the convex hull, denoted Π := conv(φ(Ω)). A simple and commonly studied case is when Ω =
[k] := {1, . . . , k} (i.e., when there are exactly k outcomes) and the securities are the Arrow-Debreu
securities that pay out $1 should a speciﬁc outcome occur and nothing otherwise (i.e., φ(ω)i = 1 if
ω = i and φ(ω)i = 0 for ω (cid:54)= i). Here, the securities are just basis vectors for Rk and Π = ∆Ω.
Traders in a prediction market hold portfolios of securities r ∈ Rk called positions that pay out a
i=1 riφ(ω)i dollars should outcome ω occur. We denote the set of positions
by R = Rk. We will assume that R always contains a position r$ that returns a dollar regardless of
which outcome occurs, meaning r$ · φ(ω) = 1 for all ω ∈ Ω. We therefore interpret r$ as “cash”
within the market in the sense that buying or selling r$ guarantees a ﬁxed change in wealth.
In order to address the questions about convergence in [2, 13] we will consider a common form of
prediction market that is run through a market maker. This is an automated agent that is willing to
buy or sell securities in return for cash. The speciﬁc and well-studied prediction market mechanism
we consider is the potential-based market maker [1]. Here, traders interact with the market maker
sequentially, and the cost for each trade is determined by a convex potential function C : R → R
applied to the market maker’s state s ∈ R. Speciﬁcally, the cost for a trade dr when the market
maker has state s is given by cost(dr; s) = C(s−dr)−C(s), i.e., the change in potential value of the
market maker’s position due to the market maker accepting the trade. After a trade, the market maker
updates the state to s ← s − dr.1 As noted in the next section, the usual axiomatic requirements for
a cost function (e.g., in [1]) specify a function that is effectively a risk measure, commonly studied
in mathematical ﬁnance (see, e.g., [9]).

2.1 Risk Measures

As in [13], agents in our framework will each quantify their uncertainty in positions using what is
known as risk measure. This is a function that assigns dollar values to positions. As Example 1
below shows, this assumption will also cover the case of agents maximizing exponential utility, as
considered in [2].

1It is more common in the prediction market literature for s to be a liability vector, tracking what the market
maker stands to lose instead of gain. Here we adopt positive positions to match the convention for risk measures.

2

A (convex monetary) risk measure is a function ρ : R → R satisfying, for all r, r(cid:48) ∈ R:

• Monotonicity: ∀ω r · φ(ω) ≤ r(cid:48) · φ(ω) =⇒ ρ(r) ≥ ρ(r(cid:48)).
• Cash invariance: ρ(r + c r$) = ρ(r) − c for all c ∈ R.

• Convexity: ρ(cid:0)λr + (1 − λ)r(cid:48)(cid:1) ≤ λρ(r) + (1 − λ)ρ(r(cid:48)) for all λ ∈ (0, 1).

• Normalization: ρ(0) = 0.

The reasonableness of these properties is usually argued as follows (see, e.g., [9]). Monotonicity
ensures that positions that result in strictly smaller payoffs regardless of the outcome are considered
more risky. Cash invariance captures the idea that if a guaranteed payment of $c is added to the
payment on each outcome then the risk will decrease by $c. Convexity states that merging positions
results in lower risk. Finally, normalization requires that holding no securities should carry no risk.
This last condition is only for convenience since any risk without this condition can trivially have its
argument translated so it holds without affecting the other three properties. A key result concerning
convex risk measures is the following representation theorem (cf. [9, Theorem 4.15], ).
Theorem 1 (Risk Representation). A functional ρ : R → R is a convex risk measure if and only if
there is a closed convex function α : Π → R∪{∞} such that ρ(r) = supπ∈relint(Π) (cid:104)π,−r(cid:105)− α(π).
Here relint(Π) denotes the relative interior of Π, the interior relative to the afﬁne hull of Π. Notice
that if f∗ denotes the convex conjugate f∗(y) := supx (cid:104)y, x(cid:105) − f (x), then this theorem states that
ρ(r) = α∗(−r), that is, ρ and α are “dual” in the same way prices and positions are dual [5, §5.4.4].
This suggests that the function α can be interpreted as a penalty function, assigning a measure of
“unlikeliness” α(π) to each expected value π of the securities deﬁned above. Equivalently, α(Ep [φ])
measures the unlikeliness of distribution p over the outcomes. We can then see that the risk is the
greatest expected loss under each distribution, taking into account the penalties assigned by α.
Example 1. A well-studied risk measure is the entropic risk relative to a reference distribution
q ∈ ∆Ω [9]. This is deﬁned on positions r ∈ R by ρβ(r) := β log Eω∼q [exp(−r · φ(ω)/β)]. The
cost function C(r) = ρβ(−r) associated with this risk exactly corresponds to the logarithmic mar-
ket scoring rule (LMSR). Its associated convex function αβ over distributions is the scaled relative
entropy αβ(p) = β KL(p| q). As discussed in [2, 13], the entropic risk is closely related to expo-
nential utility Uβ(w) := − 1
β exp(−βw). Indeed, ρβ(r) = −Uβ (Eω∼q [Uβ(r · φ(ω))]) which is just
the negative certainty equivalent of the position r — i.e., the amount of cash an agent with utility
Uβ and belief q would be willing to trade for the uncertain position r. Due to the monotonicity of
β , it follows that a trader maximizing expected utility Eω∼q [Uβ(r · φ(ω))] of holding position r
U−1
is equivalent to minimizing the entropic risk ρβ(r).

For technical reasons, in addition to the standard assumptions for convex risk measures, we will also
make two weak regularity assumptions. These are similar to properties required of cost functions in
the prediction market literature (cf. [1, Theorem 3.2]):

• Expressiveness: ρ is everywhere differentiable, and closure{∇ρ(r) : r ∈ R} = Π.
• Strict risk aversion:

the Convexity inequality is strict unless r − r(cid:48) = c r$ for some c ∈ R.
As discussed in [1], expressiveness is related to the dual formulation given above; roughly, it says
that the agent must take into account every possible expected value of the securities when calculating
the risk. Strict risk aversion says that an agent should strictly prefer a mixture of positions, unless
of course the difference is outcome-independent.
Under these assumptions, the representation result of Theorem 1 and a similar result for cost func-
tions [1, Theorem 3.2]) coincide and we are able to show that cost functions and risk measures
are exactly the same object; we write ρC(r) = C(r) when we think of C as a risk measure. Un-
folding the deﬁnition of cost now using cash invariance, we have ρC(s − dr + cost(dr; s)r$ ) =
ρC(s − dr) − cost(dr; s) = C(s − dr) − C(s − dr) + C(s) = ρC(s). Thus, we may view a
potential-based market maker as a constant-risk agent.

2.2 Trading Dynamics and Aggregation

As described above, we consider traders who approach the market maker sequentially and at random,
and select the optimal trade based on their current position, the market state, and the cost function C.

3

As we just observed, we may think of the market maker as a constant-risk agent with ρC = C. Let
us examine the optimization problem faced by the trader with position r when the current market
state is s. This trader will choose a portfolio dr∗ from the market maker so as to minimise her risk:

dr∗ ∈ arg min
dr∈Rk

ρ (r + dr − cost(dr)r$ ) = arg min
dr∈Rk

ρ(r + dr) + ρC(s − dr) .

(1)

Since, by the cash invariance of ρ and the deﬁnition of cost, the objective is ρ(r + dr) + ρC(s −
dr) − ρC(s), and ρC(s) does not depend on dr. Thus, if we think of F (r, s) = ρ(r) + ρC(s) as
a kind of “social risk”, we can deﬁne the surplus as simply the net risk taken away by an optimal
trade, namely F (r, s) − F (r + dr∗, s − dr∗).
We can now state our central question: if a set of N such traders arrive at random and execute
optimal (or perhaps near-optimal) trades with the market maker, will the market state converge to
the optimal risk, and if so how fast? As discussed in the introduction, this is precisely the question
asked in [2, 13] that we set out to answer. To do so we will draw a close connection to the literature
on distributed optimization algorithms for machine learning. Speciﬁcally, if we encode the entire
state of our system in the positions R = (r0 = s, r1, . . . , rn) of the market maker and each of the
n traders, we may view the optimal trade in eq. (1) as performing a coordinate descent step, by
optimizing only with respect to coordinates 0 and i. We build on this connection in Section 4 and
leverage a generalization of coordinate descent methods to show the following in Theorem 4: If a
set of risk-based traders is sampled at random to sequentially trade in the market, the market state
and prices converge to within  of the optimal total risk in O(1/) rounds.
In fact, under mild smoothness assumptions on the cost potential function C, we can improve this
rate to O(log(1/)). We can also relax the optimality of the trader behavior; as long as traders ﬁnd
a trade dr which extracts at least a constant fraction of the surplus, the rate remains intact.
With convergence rates in hand, the next natural question might be: to what does the market con-
verge? Abernethy et al. [2] show that when traders minimize expected exponential utility and have
exponential family beliefs, the market equilibrium price can be thought of as a weighted average of
the parameters of the traders, with the weights being a measure of their risk tolerance. Even though
our setting is far more general than exponential utility and exponential families, the framework we
develop can also be used to show that their results can be extended to interactions between traders
who have what we call “compatible” risks and beliefs. Speciﬁcally, for any risk-based trader pos-
sessing a risk ρ with dual α, we can think of that trader’s “belief” as the least surprising distribution
p according to α. This view induces a family of distributions (which happen to be generalized ex-
ponential families [11]) that are parameterized by the initial positions of the traders. Furthermore,
the risk tolerance b is given by how sensitive this belief is to small changes of an agent’s position.
The results of [2] are then a special case of our Theorem 8 for agents with ρ being entropic risk (cf.
Example 1): If each trader i has risk tolerance bi and a belief parameterized by θi, and the initial
market state is θ0, then the equilibrium state of the market, to which the market converges, is given

by θ∗ = θ0+(cid:80)
1+(cid:80)

i biθi
i bi

.

As the focus of this paper is on the convergence, the details for this result are given in Appendix C.
The main insight that drives the above analysis of the interaction between a risk-based trader and a
market maker is that each trade minimizes a global objective for the market that is the inﬁmal convo-
lution [6] of the traders’ and market maker’s risks. In fact, this observation naturally generalizes to
trades between three or more agents and the same convergence analysis applies. In other words, our
analysis also holds when bilateral trade with a ﬁxed market maker is replaced by multilateral trade
among arbitrarily overlapping subsets of agents. Viewed as a graph with agents as nodes, the stan-
dard prediction market framework is represented by the star graph, where the central market market
interacts with traders sequentially and individually. More generally we have what we call a trading
network, in which the structure of trades can form arbitrary connected graphs or even hypergraphs.
An obvious choice is the complete graph, which can model a decentralized market, and in fact we
can even compare the convergence rate of our dynamics between the centralized and decentralized
models; see Appendix D.2 and the discussion in § 5.

4

3 General Trading Dynamics

satisfying(cid:80)

The previous section described the two agent case of what is more generally known as the optimal
risk allocation problem [6] where two or more agents express their preferences for positions via
risk measures. This is formalized by considering N agents with risk measures ρi : R → R for
i ∈ [N ] := {1, . . . , N} who are asked to split a position r ∈ R in to per-agent positions ri ∈ R
i ρi(ri). They note that the value of the total
risk is given by the inﬁmal convolution ∧iρi of the individual agent risks — that is,

i ri = r so as to minimise the total risk(cid:80)
(cid:88)

(cid:40)(cid:88)

(cid:41)

ri = r , ri ∈ R

.

(2)

(∧iρi)(r) := inf

ρi(ri) :

i

i

A key property of the inﬁmal convolution, which will underly much of our analysis, is that its convex
conjugate is the sum of the conjugates of its constituent functions. See e.g. [23] for a proof.

(3)

(cid:88)

i∈[N ]

(∧iρi)∗ =

ρ∗
i .

(i.e., a matrix in RN×k) such that(cid:80)
by ΦS(r) =(cid:80)
i∈S ρi(ri)− (∧iρi)((cid:80)

if it were a single risk-based agent) as a function of the net position(cid:80)

One can think of ∧iρi as the “market risk”, which captures the risk of the entire market (i.e., as
i ri of its constituents. By
deﬁnition, eq. (2) says that the market is trying to reallocate the risk so as to minimize this net risk.
This interpretation is conﬁrmed by eq. (3) when we interpret the duals as penalty functions as above:
the penalty of π is the sum of the penalties of the market participants.
As alluded to above, we allow our agents to interact round by round by conducting trades, which are
simply the exchange of outcome-contingent securities. Since by assumption our position space R is
closed under linear combinations, a trade between two agents is simply a position which is added to
one agent and subtracted from another. Generalizing from this two agent interaction, a trade among
a set of agents S ⊆ [N ] is just a collection of trade vectors, one for each agent, which sum to 0.
Formally, let S ⊆ [N ] be a subset of agents. A trade on S is then a vector of positions dr ∈ RN
i∈S dri = 0 ∈ R and dri = 0 for all i /∈ S. This last condition

speciﬁes that agents not in S do not change their position.
A key quantity in our analysis is a measure of how much the total risk of a collection of traders drops
due to trading. Given some subset of traders S, the S-surplus is a function ΦS : RN → R deﬁned
i∈S ri) which measures the maximum achievable drop in risk
(since ∧iρi is an inﬁmum). In particular, Φ(r) := Φ[N ](r) is the surplus function. The trades that
achieve this optimal drop in risk are called efﬁcient: given current state r ∈ RN , a trade dr ∈ RN
on S ⊆ [N ] is efﬁcient if ΦS(r + dr) = 0.
Our following key result shows that efﬁcient trades have remarkable structure: once the state r and
subset S is speciﬁed, there is a unique efﬁcient trade, up to cash transfers.
In other words, the
surplus is removed from the position vectors and then redistributed as cash to the traders; the choice
of trade is merely in how this redistribution takes place. The fact that the derivatives match has strong
intuition from prediction markets: agents must agree on the price.2 The proof is in Appendix A.1.
Theorem 2. Let r ∈ RN and S ⊆ [N ] be given.
i. The surplus is always ﬁnite: 0 ≤ ΦS(r) < ∞.
ii. The set of efﬁcient trades on S is nonempty.
iii. Efﬁcient trades are unique up to zero-sum cash transfers: Given efﬁcient trades dr∗, dr ∈ RN
A trade dr on S is efﬁcient if and only if for all i, j ∈ S,
If dr is an efﬁcient trade on S, for all i ∈ S we have
π∈Π

on S, we have dr = dr∗ + (z1r$, . . . , zN r$ ) for some z ∈ RN with(cid:80)
i∈S αi(π) −(cid:10)π,(cid:80)
(cid:80)

∇ρi(ri + dri) = ∇ρj(rj + drj).
∇ρi(ri + dri) = −π∗
S, where π∗

v. There is a unique “efﬁcient price”:

iv. Traders agree on “prices”:

S = arg min

i zi = 0.

(cid:11).

i∈S ri

2As intuition for the term “price”, consider that the highest price-per-unit agent i would be willing to pay
for an inﬁnitesimal quantity of a position dri is dri · (−∇ρi(ri)), and likewise the lowest price-per-unit to sell.
Thus, the entries of −∇ρi(ri) act as the “fair” prices for their corresponding basis positions/securities.

5

The above properties of efﬁcient trades drive the remainder of our convergence analysis of network
dynamics. It also allows us to write a simple closed form for the market price when traders share
a common risk proﬁle (Theorem 8). Details are in Appendix C. Beyond our current focus on rates,
Theorem 2 has implications for a variety of other economic properties of trade networks. For ex-
ample, in Appendix B we show that efﬁcient trades correspond to ﬁxed points for more general
dynamics, market clearing equilibria, and equilibria of natural bargaining games among the traders.
Recall that in the prediction market framework of [13], each round has a single trader, say i > 1,
interacting with the market maker who we will assume has index 1. In the notation just deﬁned this
corresponds to choosing S = {1, i}. We now wish to consider richer dynamics where groups of two
or more agents trade efﬁciently each round. To this end will we call a collection S = {Sj ⊆ [N ]}m
of groups of traders a trading network and assume there is some ﬁxed distribution D over S with
full support. A trade dynamic over S is a process that begins at t = 0 with some initial positions
r0 ∈ RN for the N traders, and at each round t, draws a random group of traders St ∈ S according
to D, selects some efﬁcient trade drt on S, then updates the trader positions using rt+1 = rt + drt.
For the purposes of proving the convergence of trade dynamics, a crucial property is whether all
traders can directly or indirectly affect the others. To capture this we will say a trade network
is connected if the hypergraph on [N ] with edges given by S is connected; i.e., information can
propagate throughout the entire network. Dynamics over classical prediction markets are always
connected since any pair of groups from its network will always contain the market maker.

j=1

4 Convergence Analysis of Randomized Subspace Descent

Before brieﬂy reviewing the literature on coordinate descent, let us see why this might be a useful
way to think of our dynamics. Recall that we have a set S of subsets of agents, and that in each step,
an efﬁcient trade dr is chosen which only modiﬁes the positions of agents in the sampled S ∈ S.
Thinking of (r1, . . . , rN ) as a vector of dimension N · k vector (recall R = Rk), changing rt to
rt+1 = rt + dr thus only modiﬁes |S| blocks of k entries. Moreover, efﬁciency ensures that dr
minimizes the sum of the risks of agents in S. Hence, ignoring for now the constraint that the sum
of the positions must remain constant, the trade dynamic seems to be performing a kind of block
coordinate descent of the surplus function Φ.

4.1 Randomized Subspace Descent

Several randomized coordinate descent methods have appeared in the literature recently, with in-
creasing levels of sophistication. While earlier methods focused on updates which only modiﬁed
disjoint blocks of coordinates [18, 22], more recent methods allow for more general conﬁgurations,
such as overlapping blocks [17, 16, 20]. In fact, these last three methods are closest to what we study
here; the authors consider an objective which decomposes as the sum of convex functions on each
coordinate, and study coordinate updates which follow a graph structure, all under the constraint
that coordinates sum to 0. Despite the similarity of these methods to our trade dynamics, we require
even more general updates, as we allow coordinate i to correspond to arbitrary subsets Si ∈ S.
Instead, we establish a uniﬁcation of these methods which we call randomized subspace descent
(RSD), listed in Algorithm 1. Rather than blocks of coordinates or speciﬁc linear constraints, RSD
abstracts away these constructs by simply specifying “coordinate subspaces” in which the optimiza-
tion is to be performed. Speciﬁcally, the algorithm takes a list of projection matrices {Πi}n
i=1 which
deﬁne the subspaces, and at each step t selects a Πi at random and tries to optimize the objective
under the constraint that it may only move within the image space of Πi; that is, if the current point
is xt, then xt+1 − xt ∈ im(Πi).
Before stating our convergence results for Algorithm 1, we will need a notion of smoothness relative
to our subspaces. Speciﬁcally, we say F is Li-Πi-smooth if for all i there are constants Li > 0 such
that for all y ∈ im(Πi),

F (x + y) ≤ F (x) + (cid:104)∇F (x), y(cid:105) + Li

2 (cid:107)y(cid:107)2
2 .

(4)

Finally, let F min := miny∈span{im(Πi)}i F (x0 + y) be the global minimizer of F subject to the
constraints from the Πi. Then we have the following result for a constant R(x0) which increases in:

6

smoothness parameters {Li}m

ALGORITHM 1: Randomized Subspace Descent
Input: Smooth convex function F : Rn → R, initial point x0 ∈ Rn, matrices {Πi ∈ Rn×n}m
i=1,
for iteration t in {0, 1, 2,···} do
Πi∇F (xt)

i=1, distribution p ∈ ∆m

end

sample i from p
xt+1 ← xt − 1

Li

(1) the distance from the point x0 to furthest minimizer of F , (2) the Lipschitz constants of F w.r.t.
the Πi, and (3) the connectivity of the hypergraph induced by the projections.
Theorem 3. Let F , {Πi}i, {Li}i, x0, and p be given as in Algorithm 1, with the condition that F is

Li-Πi-smooth for all i. Then E(cid:2)F (xt) − F min(cid:3) ≤ 2R2(x0) / t.

The proof is in Appendix D. Additionally, when F is strongly convex, meaning it has a uniform local
quadratic lower bound, RSD enjoys faster, linear convergence. Formally, this condition requires F
to be µ-strongly convex for some constant µ > 0, that is, for all x, y ∈ dom F we require

F (y) ≥ F (x) + ∇F (x) · (y − x) + µ

2(cid:107)y − x(cid:107)2 .
The statement and details of this stronger result is given in Appendix D.1.
Importantly for our setting these results only track the progress per iteration. Thus, they apply to
more sophisticated update steps than a simple gradient step as long as they improve the objective
by at least as much. For example, if in each step the algorithm computed the exact minimizer
xt+1 = arg miny∈im(Πi) F (xt + y), both theorems would still hold.

(5)

of RN consisting of all possible trades on S, namely {dr ∈ RN : dri = 0 for i (cid:54)= S, (cid:80)

4.2 Convergence Rates for Trade Dynamics
To apply Theorem 3 to the convergence of trading dynamics, we let F = Φ and x = (r1, . . . , rN ) ∈
RN ∼= RN k be the joint position of all agents. For each subset S ∈ S of agents, we have a subspace
i∈S dri =
0}, with corresponding projection matrix ΠS. For the special case of prediction markets with a
centralized market maker, we have N − 1 subspaces S = {{1, i} : i ∈ {2, . . . , N}} and Π1,i
projects onto {dr ∈ RN : dri = −dr1, drj = 0 for j (cid:54)= 1, i}. The intuition of coordinate descent is
clear now: the subset S of agents seek to minimize the total surplus within the subspace of trades on
S, and thus the coordinate descent steps of Algorithm 1 will correspond to roughly efﬁcient trades.
We now apply Theorem 3 to show that trade dynamics achieve surplus  > 0 in time O(1/). Note
that we will have to assume the risk measure ρi of agent i is Li-smooth for some Li > 0. This is a
very loose restriction, as our risk measures are all differentiable by the expressiveness condition.
Theorem 4. Let ρi be an Li-smooth risk measure for all i. Then for any connected trade dynamic,
we have E [Φ(rt)] = O(1/t).
Proof. Taking LS = maxi∈S Li, one can check that F is LS-ΠS-smooth for all S ∈ S by eq. (4).
Since Algorithm 1 has no state aside from xt, and the proof of Theorem 3 depends only the drop
in F per step, any algorithm selecting the sets S ∈ S with the same distribution and satisfying
Πi∇F (xt)) will yield the same convergence rate. As trade dynamics satisfy
F (xt+1) ≤ F (xt − 1
F (xt+1) = miny∈RN k F (xt − Πiy), this property trivially holds, and so Theorem 3 applies.

Li

If we assume slightly more, that our risk measures have local quadratic lower bounds, then we can
obtain linear convergence. Note that this is also a relatively weak assumption, and holds whenever
the risk measure has a Hessian with only one zero eigenvalue (for r$) at each point. This is satisﬁed,
for example, by all the variants of entropic risk we discuss in the paper. The proof is in Appendix D.
Theorem 5. Suppose for each i we have a continuous function µi : R → R+ such that for all r,
risk ρi is µi(r)-strongly convex with respect to r$⊥ in a neighborhood of r; in other words, eq. (5)
holds for F = ρi, µ = µi(r), and all y in a neighborhood of r such that (r − y) · r$ = 0. Then for
all connected trade dynamics, E [Φ(rt)] = O(2−t).

7

|V (G)|

|E(G)|

λ2(G)

n
n
n

n(n − 1)/2

2(1−cos π
n )
2(1−cos 2π
n )

Graph
Kn
Pn
Cn
K(cid:96),k
Bk
Table 1: Algebraic connectivities for common graphs.
Figure 1: Average (in bold) of 30 market simulations
for the complete and star graphs. The empirical gap in
iteration complexity is just under 2 (cf. Fig. 3).

n − 1
n
(cid:96)k
k2k−1

(cid:96) + k

2k

n

k
2

Amazingly, the convergence rates in Theorem 4 and Theorem 5 hold for all connected trade dy-
namics. The constant hidden in the O(·) does depend on the structure of the network but can be
explicitly determined in terms its algebraic connectivity. This is discussed further in Appendix D.2.
The intuition behind these convergence rates given here is that agents in whichever group S is chosen
always trade to fully minimize their surplus. Because the proofs (in Appendix D) of these methods
merely track the reduction in surplus per trading round, the bounds apply as long as the update is at
least as good as a gradient step. In fact, we can say even more: if only an  fraction of the surplus is
taken at each round, the rates are still O(1/(t)) and O((1 − µ)t), respectively. This suggests that
our convergence results are robust with respect to the model of rationality one employs; if agents
have bounded rationality and can only compute positions which approximately minimize their risk,
the rates remain intact (up to constant factors) as long as the inefﬁciency is bounded.

5 Conclusions & Future Work

Using the tools of convex analysis to analyse the behavior of markets allows us to make precise,
quantitative statements about their global behavior. In this paper we have seen that, with appropriate
assumptions on trader behaviour, we can determine the rate at which the market will converge to
equilibrium prices, thereby closing some open questions raised in [2] and [13].
In addition, our newly proposed trading networks model allow us to consider a variety of prediction
market structures. As discussed in §3, the usual prediction market setting is centralized, and corre-
sponds to a star graph with the market maker at the center. A decentralized market where any trader
can trade with any other corresponds to a complete graph over the traders. We can also model more
exotic networks, such as two or more market maker-based prediction markets with a risk minimizing
arbitrageur or small-world networks where agents only trade with a limited number of “neighbours”.
Furthermore, because these arrangements are all instances of trade networks, we can immediately
compare the convergence rates across various constraints on how traders may interact. For example,
in Appendix D.2, we show that a market that trades through a centralized market maker incurs an
quantiﬁable efﬁciency overhead: convergence takes twice as long (see Figure 1). More generally,
we show that the rates scale as λ2(G)/|E(G)|, allowing us to make similar comparisons between
arbitrary networks; see Table 1. This raises an interesting question for future work: given some
constraints such as a bound on how many traders a single agent can trade with, the total number of
edges, etc, which network optimizes the convergence rate of the market? These new models and
the analysis of their convergence may provide new principles for building and analyzing distributed
systems of heterogeneous and self-interested learning agents.

Acknowledgments

We would like to thank Matus Telgarsky for his generous help, as well as the lively discussions with,
and helpful comments of, S´ebastien Lahaie, Miro Dud´ık, Jenn Wortman Vaughan, Yiling Chen,
David Parkes, and Nageeb Ali. MDR is supported by an ARC Discovery Early Career Research
Award (DE130101605). Part of this work was developed while he was visiting Microsoft Research.

8

References
[1] Jacob Abernethy, Yiling Chen, and Jennifer Wortman Vaughan. Efﬁcient market making via convex
optimization, and a connection to online learning. ACM Transactions on Economics and Computation,
1(2):12, 2013.

[2] Jacob Abernethy, Sindhu Kutty, S´ebastien Lahaie, and Rahul Sami. Information aggregation in expo-
nential family markets. In Proceedings of the ﬁfteenth ACM conference on Economics and computation,
pages 395–412. ACM, 2014.

[3] Jacob D Abernethy and Rafael M Frongillo. A collaborative mechanism for crowdsourcing prediction

problems. In Advances in Neural Information Processing Systems, pages 2600–2608, 2011.

[4] Aharon Ben-Tal and Marc Teboulle. An old-new concept of convex risk measures: The optimized cer-

tainty equivalent. Mathematical Finance, 17(3):449–476, 2007.

[5] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.
[6] Christian Burgert and Ludger R¨uschendorf. On the optimal risk allocation problem. Statistics & decisions,

24(1/2006):153–171, 2006.

[7] Yiling Chen and Jennifer Wortman Vaughan. A new understanding of prediction markets via no-regret
learning. In Proceedings of the 11th ACM conference on Electronic commerce, pages 189–198. ACM,
2010.

[8] Nair Maria Maia de Abreu. Old and new results on algebraic connectivity of graphs. Linear algebra and

its applications, 423(1):53–73, 2007.

[9] Hans F¨ollmer and Alexander Schied. Stochastic Finance: An Introduction in Discrete Time, volume 27

of de Gruyter Studies in Mathematics. Walter de Gruyter & Co., Berlin, 2nd edition, 2004.

[10] Rafael M Frongillo, Nicol´as Della Penna, and Mark D Reid. Interpreting prediction markets: a stochastic

approach. In Proceedings of Neural Information Processing Systems, 2012.

[11] P.D. Gr¨unwald and A.P. Dawid. Game theory, maximum entropy, minimum discrepancy and robust

Bayesian decision theory. The Annals of Statistics, 32(4):1367–1433, 2004.

[12] JB Hiriart-Urruty and C Lemar´echal. Grundlehren der mathematischen wissenschaften. Convex Analysis

and Minimization Algorithms II, 306, 1993.

[13] Jinli Hu and Amos Storkey. Multi-period trading prediction markets with connections to machine learn-

ing. In Proceedings of the 31st International Conference on Machine Learning (ICML), 2014.

[14] Jono Millin, Krzysztof Geras, and Amos J Storkey.

Isoelastic agents and wealth updates in machine
learning markets. In Proceedings of the 29th International Conference on Machine Learning (ICML-12),
pages 1815–1822, 2012.

[15] Bojan Mohar. The Laplacian spectrum of graphs. In Graph Theory, Combinatorics, and Applications,

1991.

[16] I Necoara, Y Nesterov, and F Glineur. A random coordinate descent method on large-scale optimization

problems with linear constraints. Technical Report, 2014.

[17] Ion Necoara. Random coordinate descent algorithms for multi-agent convex optimization over networks.

Automatic Control, IEEE Transactions on, 58(8):2001–2012, 2013.

[18] Yurii Nesterov. Efﬁciency of coordinate descent methods on huge-scale optimization problems. SIAM

Journal on Optimization, 22(2):341–362, 2012.

[19] Mindika Premachandra and Mark Reid. Aggregating predictions via sequential mini-trading. In Asian

Conference on Machine Learning, pages 373–387, 2013.

[20] Sashank Reddi, Ahmed Hefny, Carlton Downey, Avinava Dubey, and Suvrit Sra. Large-scale randomized-
coordinate descent methods with non-separable linear constraints. arXiv preprint arXiv:1409.2617, 2014.
[21] Mark D Reid, Rafael M Frongillo, Robert C Williamson, and Nishant Mehta. Generalized mixability via

entropic duality. In Proc. of Conference on Learning Theory (COLT), 2015.

[22] Peter Richt´arik and Martin Tak´aˇc. Iteration complexity of randomized block-coordinate descent methods

for minimizing a composite function. Mathematical Programming, 144(1-2):1–38, 2014.

[23] R.T. Rockafellar. Convex analysis. Princeton University Press, 1997.
[24] Amos J Storkey. Machine learning markets. In International Conference on Artiﬁcial Intelligence and

Statistics, pages 716–724, 2011.

9

