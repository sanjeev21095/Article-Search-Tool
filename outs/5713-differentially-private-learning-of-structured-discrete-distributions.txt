Differentially Private Learning

of Structured Discrete Distributions

Ilias Diakonikolas∗
University of Edinburgh

Moritz Hardt
Google Research

Ludwig Schmidt

MIT

Abstract

We investigate the problem of learning an unknown probability distribution over
a discrete population from random samples. Our goal is to design efﬁcient algo-
rithms that simultaneously achieve low error in total variation norm while guaran-
teeing Differential Privacy to the individuals of the population.
We describe a general approach that yields near sample-optimal and computation-
ally efﬁcient differentially private estimators for a wide range of well-studied and
natural distribution families. Our theoretical results show that for a wide variety
of structured distributions there exist private estimation algorithms that are nearly
as efﬁcient—both in terms of sample size and running time—as their non-private
counterparts. We complement our theoretical guarantees with an experimental
evaluation. Our experiments illustrate the speed and accuracy of our private esti-
mators on both synthetic mixture models and a large public data set.

1

Introduction

The majority of available data in modern machine learning applications come in a raw and unlabeled
form. An important class of unlabeled data is naturally modeled as samples from a probability
distribution over a very large discrete domain. Such data occurs in almost every setting imaginable—
ﬁnancial transactions, seismic measurements, neurobiological data, sensor networks, and network
trafﬁc records, to name a few. A classical problem in this context is that of density estimation or
distribution learning: Given a number of iid samples from an unknown target distribution, we want
to compute an accurate approximation of the distribution. Statistical and computational efﬁciency
are the primary performance criteria for a distribution learning algorithm. More speciﬁcally, we
would like to design an algorithm whose sample size requirements are information-theoretically
optimal, and whose running time is nearly linear in its sample size.
Beyond computational and statistical efﬁciency, however, data analysts typically have a variety
of additional criteria they must balance. In particular, data providers often need to maintain the
anonymity and privacy of those individuals whose information was collected. How can we reveal
useful statistics about a population, while still preserving the privacy of individuals? In this paper,
we study the problem of density estimation in the presence of privacy constraints, focusing on the
notion of differential privacy [1].

Our contributions. Our main ﬁndings suggest that the marginal cost of ensuring differential pri-
vacy in the context of distribution learning is only moderate.
In particular, for a broad class of
shape-constrained density estimation problems, we give private estimation algorithms that are nearly
as efﬁcient—both in terms of sample size and running time—as a nearly optimal non-private base-
line. As our learning algorithm approximates the underlying distribution up to small error in total
variation norm, all crucial properties of the underlying distribution are preserved. In particular, the
analyst is free to compose our learning algorithm with an arbitrary non-private analysis.

∗The authors are listed in alphabetical order.

1

Our strong positive results apply to all distribution families that can be well-approximated by piece-
wise polynomial distributions, extending a recent line of work [2, 3, 4] to the differentially private
setting. This is a rich class of distributions including several natural mixture models, log-concave
distributions, and monotone distributions amongst many other examples. Our algorithm is agnos-
tic so that even if the unknown distribution does not conform exactly to any of these distribution
families, it continues to ﬁnd a good approximation.
These surprising positive results stand in sharp contrast with a long line of worst-case hardness
results and lower bounds in differential privacy, which show separations between private and non-
private learning in various settings.
Complementing our theoretical guarantees, we present a novel heuristic method to achieve empiri-
cally strong performance. Our heuristic always guarantees privacy and typically converges rapidly.
We show on various data sets that our method scales easily to input sizes that were previously
prohibitive for any implemented differentially private algorithm. At the same time, the algorithm
approaches the estimation error of the best known non-private method for a sufﬁciently large number
of samples.

Technical overview. We brieﬂy introduce a standard model of learning an unknown probability
distribution from samples (namely, that of [5]), which is essentially equivalent to the minimax rate
of convergence in (cid:96)1-distance [6]. A distribution learning problem is deﬁned by a class C of distri-
butions. The algorithm has access to independent samples from an unknown distribution p, and its
goal is to output a hypothesis distribution h that is “close” to p. We measure the closeness between
distributions in total variation distance, which is equivalent to the (cid:96)1-distance and sometimes also
called statistical distance. In the “noiseless” setting, we are promised that p ∈ C, and the goal is
to construct a hypothesis h such that (with high probability) the total variation distance dTV (h, p)
between h and p is at most α, where α > 0 is the accuracy parameter.
The more challenging “noisy” or agnostic model captures the situation of having arbitrary (or even
adversarial) noise in the data. In this setting, we do not make any assumptions about the target distri-
bution p and the goal is to ﬁnd a hypothesis h that is almost as accurate as the “best” approximation
of p by any distribution in C. Formally, given sample access to a (potentially arbitrary) target dis-
tribution p and α > 0, the goal of an agnostic learning algorithm for C is to compute a hypothesis
distribution h such that dTV (h, p) ≤ C · optC(p) + α, where optC(p) is the total variation distance
between p and the closest distribution to it in C, and C ≥ 1 is a universal constant.
It is a folklore fact that learning an arbitrary discrete distribution over a domain of size N to constant
accuracy requires Ω(N ) samples and running time. The underlying algorithm is straightforward:
output the empirical distribution. For distributions over very large domains, a linear dependence
on N is of course impractical, and one might hope that drastically better results can be obtained
for most natural settings. Indeed, there are many natural and fundamental distribution estimation
problems where signiﬁcant improvements are possible. Consider for example the class of all uni-
modal distributions over [N ]. In sharp contrast to the Ω(N ) lower bound for the unrestricted case,
an algorithm of Birgé [7] is known to learn any unimodal distribution over [N ] with running time
and sample complexity of O(log(N )).
The starting point of our work is a recent technique [3, 8, 4] for learning univariate distributions
via piecewise polynomial approximation. Our ﬁrst main contribution is a generalization of this
technique to the setting of approximate differential privacy. To achieve this result, we exploit a con-
nection between structured distribution learning and private “Kolmogorov approximations”. More
speciﬁcally, we show in Section 3 that, for the class of structured distributions we consider, a pri-
vate algorithm that approximates an input histogram in the Kolmogorov distance combined with the
algorithmic framework of [4] yields sample and computationally efﬁcient private learners under the
total variation distance.
Our approach crucially exploits the structure of the underlying distributions, as the Kolmogorov
distance is a much weaker metric than the total variation distance. Combined with a recent private
algorithm [9], we obtain differentially private learners for a wide range of structured distributions
over [N ]. The sample complexity of our algorithms matches their non-private analogues up to a
standard dependence on the privacy parameters and a multiplicative factor of at most O(2log∗ N ),

2

∗ denotes the iterated logarithm function. The running time of our algorithm is nearly-

where log
linear in the sample size and logarithmic in the domain size.

Related Work. There is a long history of research in statistics on estimating structured families of
distributions going back to the 1950’s [10, 11, 12, 13], and it is still a very active research area [14,
15, 16]. Theoretical computer scientists have also studied these problems with an explicit focus on
the computational efﬁciency [5, 17, 18, 19, 3]. In statistics, the study of inference questions under
privacy constraints goes back to the classical work of Warner [20]. Recently, Duchi et al. [21, 22]
study the trade-off between statistical efﬁciency and privacy in a local model of privacy obtaining
sample complexity bounds for basic inference problems. We work in the non-local model and our
focus is on both statistical and computational efﬁciency.
There is a large literature on answering so-called “range queries” or “threshold queries” over an
ordered domain subject to differential privacy. See, for example, [23] as well as the recent work [24]
and many references therein. If the output of the algorithm represents a histogram over the domain
that is accurate on all such queries, then this task is equivalent to approximating a sample in Kol-
mogorov distance, which is the task we consider. Apart from the work of Beimel et al. [25] and Bun
et al. [9], to the best of our knowledge all algorithms in this literature (e.g., [23, 24]) have a running
time that depends polynomially on the domain size N. Moreover, except for the aforementioned
works, we know of no other algorithm that achieves a sub-logarithmic dependence on the domain
size in its approximation guarantee. Of all algorithms in this area, we believe that ours is the ﬁrst
implemented algorithm that scales to very large domains with strong empirical performance as we
demonstrate in Section 5.

= maxj∈[N ] |(cid:80)j

i=1 p(i) −(cid:80)j

def

i∈S p(i). The total variation distance between two distributions p and q over [N ] is dTV (p, q)

(cid:96)1-norm of a vector v ∈ RN (or equivalently, a function from [N ] to R) is (cid:107)v(cid:107)1 = (cid:80)N
(cid:80)

2 Preliminaries
Notation and basic deﬁnitions. For N ∈ Z+, we write [N ] to denote the set {1, . . . , N}. The
i=1 |vi|.
[N ] → [0, 1], we write p(i) to denote the probabil-
For a discrete probability distribution p :
ity of element i ∈ [N ] under p. For a subset of the domain S ⊆ [N ], we write p(S) to denote
def
=
maxS⊆[N ] |p(S) − q(S)| = (1/2) · (cid:107)p − q(cid:107)1. The Kolmogorov distance between p and q is deﬁned
i=1 q(i)|. Note that dK(p, q) ≤ dTV (p, q). Given a set
as dK(p, q)
distribution(cid:98)pn : [N ] → [0, 1] is deﬁned as follows: for all i ∈ [N ],(cid:98)pn(i) = |{j ∈ [n] | sj = i}| /n.
S of n independent samples s1, . . . , sn drawn from a distribution p : [N ] → [0, 1], the empirical
Deﬁnition 1 (Distribution Learning). Let C be a family of distributions over a domain Ω. Given
sample access to an unknown distribution p over Ω and 0 < α, β < 1, the goal of an (α, β)-agnostic
learning algorithm for C is to compute a hypothesis distribution h such that with probability at least
1 − β it holds dTV (h, p) ≤ C · optC(p) + α , where optC(p) := inf q∈C dTV (q, p) and C ≥ 1 is a
universal constant.
Differential Privacy. A database D ∈ [N ]n is an n-tuple of items from [N ]. Given a database
D = (d1, . . . , dn), we let hist(D) denote the normalized histogram corresponding to D. That is,
hist(D) = 1
n
Deﬁnition 2 (Differential Privacy). A randomized algorithm M : [N ]n → R (where R is some
arbitrary range) is (, δ)-differentially private if for all pairs of inputs D, D(cid:48) ∈ [N ]n differing in
only one entry, we have that for all subsets of the range S ⊆ R, the algorithm satisﬁes:

i=1 edi, where ej denotes the j-th standard basis vector in RN .

(cid:80)n

Pr[M (D) ∈ S] ≤ exp() Pr[M (D(cid:48)) ∈ S] + δ.

In the context of private distribution learning, the database D is the sample set S from the unknown
target distribution p. In this case, the normalized histogram corresponding to D is the same as the

empirical distribution corresponding to S, i.e., hist(S) =(cid:98)pn(S).

Basic tools from probability. We recall some probabilistic inequalities that will be crucial for our
analysis. Our ﬁrst tool is the well-known VC inequality. Given a family of subsets A over [N ], deﬁne
(cid:107)p(cid:107)A = supA∈A |p(A)|. The VC–dimension of A is the maximum size of a subset X ⊆ [N ] that is
shattered by A (a set X is shattered by A if for every Y ⊆ X some A ∈ A satisﬁes A ∩ X = Y ).

3

Theorem 1 (VC inequality, [6, p. 31]). Let(cid:98)pn be an empirical distribution of n samples from p. Let
A be a family of subsets of VC–dimension k. Then E [(cid:107)p −(cid:98)pn(cid:107)A] ≤ O((cid:112)k/n).

We note that the RHS above is best possible (up to constant factors) and independent of the domain
size N. The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality [26] can be obtained as a consequence
of the VC inequality by taking A to be the class of all intervals. The DKW inequality implies that
for n = Ω(1/2), with probability at least 9/10 (over the draw of n samples from p) the empirical

distribution(cid:98)pn will be -close to p in Kolmogorov distance.
Theorem 2 ([6, p. 17]). Let A be a family of subsets over [N ], and(cid:98)pn be an empirical distribution

We will also use the following uniform convergence bound:
of n samples from p. Let X be the random variable (cid:107)p − ˆp(cid:107)A. Then we have Pr [X − E[X] > η] ≤
e−2nη2

.

Connection to Synthetic Data. Distribution learning is closely related to the problem of generat-
ing synthetic data. Any dataset D of size n over a universe X can be interpreted as a distribution
over the domain {1, . . . ,|X|}. The weight of item x ∈ X corresponds to the fraction of elements in
D that are equal to x. In fact, this histogram view is convenient in a number of algorithms in Differ-
ential Privacy. If we manage to learn this unknown distribution, then we can take n samples from it
obtain another synthetic dataset D(cid:48). Hence, the quality of the distribution learner dictates the statis-
tical properties of the synthetic dataset. Learning in total variation distance is particularly appealing
from this point of view. If two datasets represented as distributions p, q satisfy dTV (p, q) ≤ α, then
for every test function f : X → {0, 1} we must have that |Ex∼pf (x) − Ex∼qf (x)| ≤ α. Put in dif-
ferent terminology, this means that the answer to any statistical query1 differs by at most α between
the two distributions.

3 A Differentially Private Learning Framework

In this section, we describe our private distribution learning upper bounds. We start with the simple
case of privately learning an arbitrary discrete distribution over [N ]. We then extend this bound to
the case of privately and agnostically learning a histogram distribution over an arbitrary but known
partition of [N ]. Finally, we generalize the recent framework of [4] to obtain private agnostic learn-
ers for histogram distributions over an arbitrary unknown partition, and more generally piecewise
polynomial distributions.
Our ﬁrst theorem gives a differentially private algorithm for arbitrary distributions over [N ] that es-
sentially matches the best non-private algorithm. Let CN be the family of all probability distributions
over [N ]. We have the following:
Theorem 3. There is a computationally efﬁcient (, 0)-differentially private (α, β)-learning algo-
rithm for CN that uses n = O((N + log(1/β))/α2 + N log(1/β)/(α)) samples.
The algorithm proceeds as follows: Given a dataset S of n samples from the unknown target dis-

tribution p over [N ], it outputs the hypothesis h = hist(S) + η = (cid:98)pn(S) + η, where η ∈ RN is

sampled from the N-dimensional Laplace distribution with standard deviation 1/(n). The simple
analysis is deferred to Appendix A.
A t-histogram over [N ] is a function h : [N ] → R that is piecewise constant with at most t interval
pieces, i.e., there is a partition I of [N ] into intervals I1, . . . , It such that h is constant on each
Ii. Let Ht(I) be the family of all t-histogram distributions over [N ] with respect to partition I =
{I1, . . . , It}. Given sample access to a distribution p over [N ], our goal is to output a hypothesis
h : [N ] → [0, 1] that satisﬁes dTV (h, p) ≤ C · optt(p) + α, where optt(p) = inf g∈Ht(I) dTV (g, p).
We show the following:
Theorem 4. There is a computationally efﬁcient (, 0)-differentially private (α, β)-agnostic learn-
ing algorithm for Ht(I) that uses n = O((t + log(1/β))/α2 + t log(1/β)/(α)) samples.
The main idea of the proof is that the differentially private learning problem for Ht(I) can be
reduced to the same problem over distributions of support [t]. The theorem then follows by an

1A statistical query asks for the average of a predicate over the dataset.

4

application of Theorem 3. See Appendix A for further details. Theorem 4 gives differentially private
learners for any family of distributions over [N ] that can be well-approximated by histograms over
a ﬁxed partition, including monotone distributions and distributions with a known mode.
In the remainder of this section, we focus on approximate privacy, i.e., (, δ)-differential privacy for
δ > 0, and show that for a wide range of natural and well-studied distribution families there exists a
computationally efﬁcient and differentially private algorithm whose sample size is at most a factor
of 2O(log∗ N ) worse than its non-private counterpart. In particular, we give a differentially private
version of the algorithm in [4]. For a wide range of distributions, our algorithm has near-optimal
sample complexity and runs in time that is nearly-linear in the sample size and logarithmic in the
domain size.
We can view our overall private learning algorithm as a reduction. For the sake of concreteness,
we state our approach for the case of histograms, the generalization to piecewise polynomials being
essentially identical. Let Ht be the family of all t-histogram distributions over [N ] (with unknown
partition). In the non-private setting, a combination of Theorems 1 and 2 (see appendix) implies that
starts with the empirical distribution(cid:98)pn and post-processes it to obtain an (α, β)-accurate hypothesis
Ht is (α, β)-agnostically learnable using n = Θ((t + log(1/β))/α2) samples. The algorithm of [4]
intervals. The important property of the empirical distribution(cid:98)pn is that with high probability,(cid:98)pn is
h. Let Ak be the collection of subsets of [N ] that can be expressed as unions of at most k disjoint
α-close to the target distribution p in Ak-distance for any k = O(t).
The crucial observation that enables our generalization is that the algorithm of [4] achieves the
same performance guarantees starting from any hypothesis q such that (cid:107)p − q(cid:107)AO(t) ≤ α.2 This
empirical distribution(cid:98)pn, efﬁciently construct an (, δ)-differentially private hypothesis q such that
observation motivates the following two-step differentially private algorithm: (1) Starting from the
with probability at least 1 − β/2 it holds (cid:107)q −(cid:98)pn(cid:107)AO(t) ≤ α/2. (2) Pass q as input to the learning
private. Recall that with probability at least 1 − β/2 we have (cid:107)p − (cid:98)pn(cid:107)AO(t) ≤ α/2. By the
properties of q in Step (1), a union bound and an application of the triangle inequality imply that
with probability at least 1 − β we have (cid:107)p − q(cid:107)AO(t) ≤ α. Hence, the output h of Step (2) is an
(α, β)-accurate agnostic hypothesis.
We have thus sketched a proof of the following lemma:
Lemma 1. Suppose there is an (, δ)-differentially private synthetic data algorithm under the
AO(t)–distance metric that is (α/2, β/2)-accurate on databases of size n, where n = Ω((t +
log(1/β))/α2). Then, there exists an (α, β)-accurate agnostic learning algorithm for Ht with sam-
ple complexity n.

algorithm of [4] with parameters (α/2, β/2) and return its output hypothesis h.
We now proceed to sketch correctness. Since q is (, δ)-differentially private and the algorithm of
Step (2) is only a function of q, the composition theorem implies that h is also (, δ)-differentially

Recent work of Bun et al. [9] gives an efﬁcient differentially private synthetic data algorithm under
the Kolmogorov distance metric:
Proposition 1. [9] There is an (, δ)-differentially private (α, β)-accurate synthetic data algorithm
with respect to dK–distance on databases of size n over [N ], assuming n = Ω((1/(α))· 2O(log∗ N )·
ln(1/αβδ)). The algorithm runs in time O(n · log N ).
Note that the Kolmogorov distance is equivalent to the A2-distance up to a factor of 2. Hence, by
applying the above proposition for α(cid:48) = α/t one obtains an (α, β)-accurate synthetic data algorithm
with respect to the At-distance. Combining the above, we obtain the following:
Theorem 5. There is an (, δ)-differentially private (α, β)-agnostic learning algorithm for Ht that
uses n = O((t/α2) · ln(1/β) + (t/(α)) · 2O(log∗ N ) · ln(1/αβδ)) samples and runs in time

(cid:101)O(n) + O(n · log N ).

As an immediate corollary of Theorem 5, we obtain nearly-sample optimal and computationally
efﬁcient differentially private estimators for all the structured discrete distribution families studied

2We remark that a potential difference is in the running time of the algorithm, which depends on the support

and structure of the distribution q.

5

in [3, 4]. These include well-known classes of shape restricted densities including (mixtures of)
unimodal and multimodal densities (with unknown mode locations), monotone hazard rate (MHR)
and log-concave distributions, and others. Due to space constraints, we do not enumerate the full
descriptions of these classes or statements of these results here but instead refer the interested reader
to [3, 4].

4 Maximum Error Rule for Private Kolmogorov Distance Approximation

In this section, we describe a simple and fast algorithm for privately approximating an input his-
togram with respect to the Kolmogorov distance. Our private algorithm relies on a simple (non-
private) iterative greedy algorithm to approximate a given histogram (empirical distribution) in Kol-
mogorov distance, which we term MAXIMUMERRORRULE. This algorithm performs a set of basic
operations on the data and can be effectively implemented in the private setting.
To describe the non-private version of MAXIMUMERRORRULE, we point out a connection of the
Kolmogorov distance approximation problem to the problem of approximating a monotone univari-

ate function with by a piecewise linear function. Let(cid:98)pn be the empirical probability distribution over
[N ], and let (cid:98)Pn denote the corresponding empirical CDF. Note that (cid:98)Pn : [N ] → [0, 1] is monotone
non-decreasing and piecewise constant with at most n pieces. We would like to approximate(cid:98)pn by

a piecewise uniform distribution with a corresponding a piecewise linear CDF. It is easy to see that
this is exactly the problem of approximating a monotone function by a piecewise linear function in
(cid:96)∞-norm.
The MAXIMUMERRORRULE works as follows: Starting with the trivial linear approximation that
interpolates between (0, 0) and (N, 1), the algorithm iteratively reﬁnes its approximation to the
target empirical CDF using a greedy criterion.
In each iteration, it ﬁnds the point (x, y) of the

true curve (empirical CDF (cid:98)Pn) at which the current piecewise linear approximation disagrees most

strongly with the target CDF (in (cid:96)∞-norm). It then reﬁnes the previous approximation by adding the
point (x, y) and interpolating linearly between the new point and the previous two adjacent points of
the approximation. See Figure 1 for a graphical illustration of our algorithm. The MAXIMUMER-
RORRULE is a popular method for monotone curve approximation whose convergence rate has been
analyzed under certain assumptions on the structure of the input curve. For example, if the mono-
tone input curve satisﬁes a Lipschitz condition, it is known that the (cid:96)∞-error after T iterations scales
as O(1/T 2) (see, e.g., [27] and references therein).
There are a number of challenges towards making this algorithm differentially private. The ﬁrst is
that we cannot exactly select the maximum error point. Instead, we can only choose an approximate
maximizer using a differentially private sub-routine. The standard algorithm for choosing such
a point would be the exponential mechanism of McSherry and Talwar [28]. Unfortunately, this
algorithm falls short of our goals in two respects. First, it introduces a linear dependence on the
domain size in the running time making the algorithm prohibitively inefﬁcient over large domains.
Second, it introduces a logarithmic dependence on the domain size in the error of our approximation.
In place of the exponential mechanism, we design a sub-routine using the “choosing mechanism”
of Beimel, Nissim, and Stemmer [25]. Our sub-routine runs in logarithmic time in the domain size
and achieves a doubly-logarithmic dependence in the error. See Figure 2 for a pseudocode of our
algorithm. In the description of the algorithm, we think of At as a CDF deﬁned by a sequence of
points (0, 0), (x1, y1), ..., (xk, yk), (N, 1) specifying the value of the CDF at various discrete points
of the domain. We denote by weight(I, At) ∈ [0, 1] the weight of the interval I according to the
CDF At, where the value at missing points in the domain is achieved by linear interpolation. In other
words, At represents a piecewise-linear CDF (corresponding to a piecewise constant histogram).
Similarly, we let weight(I, S) ∈ [0, 1] denote the weight of interval I according to the sample S,
that is, |S ∩ I|/|S|.
We show that our algorithm satisﬁes (, δ)-differential privacy (see Appendix B):
Lemma 2. For every  ∈ (0, 2), δ > 0, MaximumErrorRule satisﬁes (, δ)-differential privacy.

Next, we provide two performance guarantees for our algorithm. The ﬁrst shows that the running
time per iteration is at most O(n log N ). The second shows that if at any step t there is a “bad”
interval in I that has large error, then our algorithm ﬁnds such a bad interval where the quantitative

6

Figure 1: CDF approximation after T = 0, 1, 2, 3 iterations.

MAXIMUMERRORRULE(S ∈ [N ]n, privacy parameters , δ)
For t = 1 to T :

1. I = FINDBADINTERVAL(At−1, S)
2. At = UPDATE(At−1, S, I)

FINDBADINTERVAL

1. Let I be the collection of all dyadic intervals of the domain.
2. For each J ∈ I, let q(J; S) = |weight(J, At−1) − weight(J, S)|.
3. Output an I ∈ I sampled from the choosing mechanism with score function q over the

collection I with privacy parameters (/2T, δ/T ).

UPDATE

1. Let I = (l, r) be the input

interval.

Compute wl = weight([1, l], S) +

Laplace(0, 1/(2n)) and wr = weight([l + 1, r], S) + Laplace(0, 1/(2n)).

2. Output the CDF obtained from At−1 by adding the points (l, wl) and (r, wl + wr) to the

graph of At−1.

Figure 2: Maximum Error Rule (MERR).

loss depends only doubly-logarithmically on the domain size (see Appendix B for the proof of the
following theorem).
Proposition 2. MERR runs in time O(T n log N ). Furthermore, for every step t, with probability
1 − β, we have that the interval I selected at step t satisﬁes

(cid:18) 1

n

· log(cid:0)n log N · log(1/βδ)(cid:1)(cid:19)

.

|weight(I, At−1) − weight(I, S)| ≥ OPT − O

Recall that OPT = maxJ∈I |weight(J, At−1) − weight(J, S)|.

5 Experiments

In addition to our theoretical results from the previous sections, we also investigate the empirical
performance of our private distribution learning algorithm based on the maximum error rule. The
focus of our experiments is the learning error achieved by the private algorithm for various distribu-
tions. For this, we employ two types of data sets: multiple synthetic data sets derived from mixtures
of well-known distributions (see Appendix C), and a data set from Higgs experiments [29]. The
synthetic data sets allow us to vary a single parameter (in particular, the domain size) while keeping
the remaining problem parameters constant. We have chosen a distribution from the Higgs data set
because it gives rise to a large domain size. Our results show that the maximum error rule ﬁnds
a good approximation of the underlying distribution, matching the learning error of a non-private
baseline when the number of samples is sufﬁciently large. Moreover, our algorithm is very efﬁcient
and runs in less than 5 seconds for n = 107 samples on a domain of size N = 1018.
We implemented our algorithm in the Julia programming language (v0.3) and ran the experiments on
an Intel Core i5-4690K CPU (3.5 - 3.9 GHz, 6 MB cache). In all experiments involving our private
learning algorithm, we set the privacy parameters to  = 1 and δ = 1
n. Since the noise magnitude
n, varying  has the same effect as varying the the sample size n. Similarly, changes in
depends on 1
δ are related to changes in n, and therefore we only consider this setting of privacy parameters.

7

Higgs data.
In addition to the synthetic data mentioned above, we use the lepton pT (transverse
momentum) feature of the Higgs data set (see Figure 2e of [29]). The data set contains roughly
11 million samples, which we use as unknown distribution. Since the values are speciﬁed with 18
digits of accuracy, we interpret them as discrete values in [N ] for N = 1018. We then generate a
sample from this data set by taking the ﬁrst n samples and pass this subset as input to our private
distribution learning algorithm. This time, we measure the error as Kolmogorov distance between
the hypothesis returned by our algorithm and the cdf given by the full set of 11 million samples.
In this experiment (Figure 3), we again see that the maximum-error rule achieves a good learning
error. Moreover, we investigate the following two aspects of the algorithm: (i) The number of steps
taken by the maximum error rule inﬂuences the learning error. In particular, a smaller number of
steps leads to a better approximation for small values of n, while more samples allow us to achieve
a better error with a larger number of steps. (ii) Our algorithm is very efﬁcient. Even for the largest
sample size n = 107 and the largest number of MERR steps, our algorithm runs in less than 5
seconds. Note that on the same machine, simply sorting n = 107 ﬂoating point numbers takes about
0.6 seconds. Since our algorithm involves a sorting step, this shows that the overhead added by
the maximum error rule is only about 7× compared to sorting. In particular, this implies that no
algorithm that relies on sorted samples can outperform our algorithm by a large margin.

Limitations and future work. As we previously saw, the performance of the algorithm varies
with the number of iterations. Currently this is a parameter that must be optimized over separately,
for example, by choosing the best run privately from the exponential mechanism. This is standard
practice in the privacy literature, but it would be more appealing to ﬁnd an adaptive method of
choosing this parameter on the ﬂy as the algorithm obtains more information about the data.
There remains a gap in sample complexity between the private and the non-private algorithm. One
reason for this are the relatively large constants in the privacy analysis of the choosing mecha-
nism [9]. With a tighter privacy analysis, one could hope to reduce the sample size requirements of
our algorithm by up to an order of magnitude.
It is likely that our algorithm could also beneﬁt from certain post-processing steps such as smoothing
the output histogram. We did not evaluate such techniques here for simplicity and clarity of the
experiments, but this is a promising direction.

Higgs data

Higgs data

100

10−1

10−2

r
o
r
r
e
-
v
o
r
o
g
o
m
l
o
K

10−3

103

)
s
d
n
o
c
e
s
(

e
m

i
t

g
n
i
n
n
u
R

100

10−1

104

105

106

107

103

104

105

106

107

Sample size n

Sample size n

m = 4

m = 8

m = 12

m = 16

m = 20

Figure 3: Evaluation of our private learning algorithm on the Higgs data set. The left plot shows the
Kolmogorov error achieved for various sample sizes n and number of steps taken by the maximum
error rule (m). The right plot displays the corresponding running times of our algorithm.

Acknowledgments

Ilias Diakonikolas was supported by EPSRC grant EP/L021749/1 and a Marie Curie Career In-
tegration grant. Ludwig Schmidt was supported by MADALGO and a grant from the MIT-Shell
Initiative.

8

References
[1] C. Dwork. The differential privacy frontier (extended abstract). In TCC, pages 496–502, 2009.
[2] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Learning mixtures of structured distributions over

discrete domains. In SODA, 2013.

[3] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Efﬁcient density estimation via piecewise polynomial

approximation. In STOC, pages 604–613, 2014.

[4] J. Acharya, I. Diakonikolas, J. Li, and L. Schmidt. Sample-Optimal Density Estimation in Nearly-Linear

Time. Available at http://arxiv.org/abs/1506.00671, 2015.

[5] M. Kearns, Y. Mansour, D. Ron, R. Rubinfeld, R. Schapire, and L. Sellie. On the learnability of discrete

distributions. In Proc. 26th STOC, pages 273–282, 1994.

[6] L. Devroye and G. Lugosi. Combinatorial methods in density estimation. Springer Series in Statistics,

Springer, 2001.

[7] L. Birgé. Estimation of unimodal densities without smoothness assumptions. Annals of Statistics,

25(3):970–981, 1997.

[8] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Near-optimal density estimation in near-linear time

using variable-width histograms. In NIPS, pages 1844–1852, 2014.

[9] M. Bun, K. Nissim, U. Stemmer, and S. P. Vadhan. Differentially private release and learning of threshold

functions. CoRR, abs/1504.07553, 2015.

[10] U. Grenander. On the theory of mortality measurement. Skand. Aktuarietidskr., 39:125–153, 1956.
[11] B.L.S. Prakasa Rao. Estimation of a unimodal density. Sankhya Ser. A, 31:23–36, 1969.
[12] P. Groeneboom. Estimating a monotone density. In Proc. of the Berkeley Conference in Honor of Jerzy

Neyman and Jack Kiefer, pages 539–555, 1985.

[13] L. Birgé. Estimating a density under order restrictions: Nonasymptotic minimax risk. Ann. of Stat., pages

995–1012, 1987.

[14] F. Balabdaoui and J. A. Wellner. Estimation of a k-monotone density: Limit distribution theory and the

spline connection. The Annals of Statistics, 35(6):pp. 2536–2564, 2007.

[15] L. D umbgen and K. Ruﬁbach. Maximum likelihood estimation of a log-concave density and its distribu-

tion function: Basic properties and uniform consistency. Bernoulli, 15(1):40–68, 2009.
[16] G. Walther. Inference and modeling with log-concave distributions. Stat. Science, 2009.
[17] Y. Freund and Y. Mansour. Estimating a mixture of two product distributions. In COLT, 1999.
[18] J. Feldman, R. O’Donnell, and R. Servedio. Learning mixtures of product distributions over discrete

domains. In FOCS, pages 501–510, 2005.

[19] C. Daskalakis, I. Diakonikolas, and R.A. Servedio. Learning k-modal distributions via testing. In SODA,

pages 1371–1385, 2012.

[20] S. L. Warner. Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias. Journal

of the American Statistical Association, 60(309), 1965.

[21] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax rates. In FOCS,

pages 429–438, 2013.

[22] J. C. Duchi, M. J. Wainwright, and M. I. Jordan. Local privacy and minimax bounds: Sharp rates for

probability estimation. In NIPS, pages 1529–1537, 2013.

[23] M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for differentially-private data

release. In NIPS, 2012.

[24] C. Li, M. Hay, G. Miklau, and Y. Wang. A data- and workload-aware query answering algorithm for

range queries under differential privacy. PVLDB, 7(5):341–352, 2014.

[25] A. Beimel, K. Nissim, and U. Stemmer. Private learning and sanitization: Pure vs. approximate differen-

tial privacy. In RANDOM, pages 363–378, 2013.

[26] A. Dvoretzky, J. Kiefer, and J. Wolfowitz. Asymptotic minimax character of the sample distribution
function and of the classical multinomial estimator. Ann. Mathematical Statistics, 27(3):642–669, 1956.
[27] G. Rote. The convergence rate of the sandwich algorithm for approximating convex functions. Computing,

48:337–361, 1992.

[28] F. McSherry and K. Talwar. Mechanism design via differential privacy. In FOCS, pages 94–103, 2007.
[29] Pierre Baldi, Peter Sadowski, and Daniel Whiteson. Searching for exotic particles in high-energy physics

with deep learning. Nature Communications, (5), 2014.

[30] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and differential privacy. In FOCS, 2010.

9

