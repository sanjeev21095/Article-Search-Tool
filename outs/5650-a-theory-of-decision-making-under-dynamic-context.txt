A Theory of Decision Making Under Dynamic

Context

Princeton Neuroscience Institute

Department of Mechanical and Aerospace Engineering

Michael Shvartsman

Princeton University
Princeton, NJ, 08544

ms44@princeton.edu

Vaibhav Srivastava

Princeton University
Princeton, NJ, 08544

vaibhavs@princeton.edu

Jonathan D. Cohen

Princeton Neuroscience Institute

Princeton University
Princeton, NJ, 08544

jdc@princeton.edu

Abstract

The dynamics of simple decisions are well understood and modeled as a class
of random walk models [e.g. 1–4]. However, most real-life decisions include a
dynamically-changing inﬂuence of additional information we call context. In this
work, we describe a computational theory of decision making under dynamically
shifting context. We show how the model generalizes the dominant existing model
of ﬁxed-context decision making [2] and can be built up from a weighted combi-
nation of ﬁxed-context decisions evolving simultaneously. We also show how the
model generalizes recent work on the control of attention in the Flanker task [5].
Finally, we show how the model recovers qualitative data patterns in another task
of longstanding psychological interest, the AX Continuous Performance Test [6],
using the same model parameters.

1

Introduction

In the late 1940s, Wald and colleagues developed a sequential test called the sequential probability
ratio test (SPRT; [7]). This test accumulates evidence in favor of one of two simple hypotheses until
a log likelihood threshold is crossed and one hypothesis is selected, forming a random walk to a
decision bound. This test was quickly applied as a model of human decision making behavior both
in its discrete form [e.g. 1] and in a continuous realization as biased Wiener process (the Diffusion
Decision Model or DDM; [2]). This work has seen a recent revival due to evidence of neurons that
appear to reﬂect ramping behavior consistent with evidence accumulation [e.g. 8], cortical circuits
implementing a decision process similar to the SPRT in the basal ganglia in rats [9], and the ﬁnding
correlations between DDM parameters and activity in EEG [10] and fMRI [11].
Bolstered by this revival, a number of groups investigated extension models. Some of these models
tackle complex hypothesis spaces [e.g. 12], or greater biological realism [e.g. 13]. Others focus
on relaxing stationarity assumptions about the task setting, whether by investigating multi-stimulus
integration [5], deadlines [14], or different evidence distribution by trial [15].
We engage with the latter literature by providing a theory of multi-alternative decision making under
dynamically changing context. We deﬁne context simply as additional information that may bear
upon a decision, whether from perception or memory. Such a theory is important because even
simple tasks that use apparently-ﬁxed contexts such as prior biases may require inference on the

1

context itself before it can bear on the decision. The focus on dynamics is what distinguishes our
work from efforts on context-dependent changes in preferences [e.g. 16] and internal context updat-
ing [e.g. 17]. The admission of evidence from memory distinguishes it from work on multisensory
integration [e.g. 18].
We illustrate such decisions with an example: consider seeing someone that looks like a friend (a
target stimulus), and a decision: to greet or not greet this person. A context can be external (e.g.
a concert hall) or internal (e.g. the memory that the friend went on vacation, and therefore this
person is likely a lookalike). The context can strictly constrain the decision (e.g. greeting a friend
in the street vs. the middle of a ﬁlm), or only bias it (guessing whether this is a friend or lookalike
after retrieving the memory of them on vacation). Regardless, context affects the decision, and we
assume it needs to be inferred, either before or alongside the greeting decision itself. We aim to
build a normative theory of this context processing component of decision making. We show that
our theory generalizes the discrete-time context-free SPRT (and therefore a Wiener process DDM in
continuous time) and how context-dependent decisions can be optimally built up from a dynamically
weighted combination of context-free decisions.
Our theory is general enough to consider a range of existing empirical paradigms in the literature,
including the Stroop, Flanker, Simon, and the AX-CPT [6, 19–21]. We choose to mention these in
particular because they reside on the bounds of the task space our theory considers on two different
dimensions, and describe a discretization of task space on those dimensions that accommodates
those existing paradigms. We show that in spite of the framework’s generality, it can provide well-
behaved zero-parameter predictions across qualitatively different tasks. We do this by using our
framework to derive a notational variant of an existing Flanker model [5], and using parameter values
from this previous model to simultaneously generate qualitatively accurate predictions in both the
ﬂanker and AX-CPT paradigms. That is, our theory generates plausible behavior in qualitatively
different tasks, using the same parameters.

2 The theoretical framework

We assume that dynamic context decision making, like ﬁxed context decision making, can be un-
derstood as a sequential Bayesian inference process. Our theory therefore uses sequentially drawn
samples from external input and/or internal memory to compute the joint posterior probability over
the identity of the true context and decision target over time. It maps from this joint probability to
a response probability using a ﬁxed response mapping, and uses a ﬁxed threshold rule deﬁned over
the response probability to stop sampling and respond. We make a distinction between our theory
of decision making and individual task models that can be derived from the theory by picking points
in task space that the theory accommodates.
Formally, we assume the decider conditions a decision based on its best estimate of two pieces of
information: some unknown true context taking on one of the values {ci}n
i=0, and some unknown
true target taking on one of the values {gj}m
j=0. This intentionally abstracts from richer views of
context (e.g. ones which assume that the context is qualitatively different from the target, or that the
relevant context to sample from is unknown). We denote by C, G random variables representing the
possible draws of context and target, and r(·) a deterministic function from the distribution P (C, G)
to a distribution over responses. We deﬁne an abstract context sensor and target sensor selectively
tuned to context or target information, such that eC is a discrete piece of evidence drawn from the
context sensor, and eG one drawn from the target sensor. The goal of the decider is to average over
the noise in the sensors to estimate the pair (C, G) sufﬁciently to determine the correct response,
and we assume that this inference is done optimally using Bayes’ rule.
c ≥ ton
the time at which it disap-
We denote by ton
c
the time at which the target appears and disappears. We also restrict
pears, and likewise ton
these times such that ton
g ; this is the primary distinction between context and target, which
can otherwise be two arbitrary stimuli. The onsets and offsets deﬁne one dimension in a continuous
space of tasks over which our theory can make predictions.
The form of r(·) deﬁnes a second dimension in the space of possible tasks where our theory makes
predictions. We use a suboptimal but simple threshold heuristic for the decision rule: when the a

the time at which the context appears and tof f
g ≤ tof f
c ≤ ton

g

c

2

g

c = ton

g and tof f

c = tof f
c ≤ ton

posteriori probability of any response crosses some adaptively set threshold, sampling ends and the
response is made in favor of that response.
For the purposes of this paper, we restrict ourselves to two extremes on both of these dimensions.
For stimulus onset and offset times, we consider one setting where the context and target appear
), and one where the target
and disappear together (perfect overlap, i.e. ton
appears some time after the context disappears (no overlap, i.e. tof f
g ). We label the former the
external context model, because the contextual information is immediately available, and the latter
the internal context model, because the information must be previously encoded and maintained.
The external context model is like the ongoing ﬁlm context from the introduction, and the internal
context is like knowing that the friend is on vacation.
For the response mapping function r(·) we consider one setting where the response is solely con-
ditioned on the perceptual target (context-independent response) and one where the response is is
conditioned jointly on the context-target pair (context-dependent response). The context-dependent
response is like choosing to greet or not greet the friend at the movie theater, and the context-
independent one is like choosing to greet or not greet the friend on the street.
In the lab, classic tasks like the Stroop, Flanker, and Simon [19–21] fall into the taxonomy as
external-context tasks with a context-independent response, because the response is solely condi-
tioned on the perceptual target. On the other side of both dimensions are tasks like the N-back task
and the AX Continuous Performance Test [6]. In our consideration of these tasks, we restrict our
attention to the case where there are only two possible context and target hypotheses. The sequential
inference procedure we use can be performed for other numbers of potentially-dependent hypotheses
and responses, though the analysis we show later in the paper relies on the n = m = 2 assumption
and on indepednence between the two sensors.

3 External context update

First we describe the inference procedure in the case of perfect overlap of context and target. At the
current timestep τ, the decider has available evidence samples from both the context and the target
(eC and eG) and uses Bayes’ rule to compute the posterior probability P (C, G | eC, eG):

Pτ (C = c, G = g | eC , eG) ∝ P (eC , eG | C = c, G = g)Pτ−1(C = c, G = g)

(1)
The ﬁrst term is the likelihood of the evidence given the joint context-target hypothesis, and the
second term is the prior, which we take to be the posterior from the previous time step. We use
the ﬂanker task as a concrete example. In this task, participants are shown a central target (e.g. an
S or an H) surrounded on both sides by distractors (‘ﬂankers’, more S or H stimuli) that are either
congruent or incongruent with it. Participants are told to respond to the target only but show a
number of indications of inﬂuence of the distractor, most notably an early period of below-chance
performance and a slowdown or reduced accuracy with incongruent relative to congruent ﬂankers
[20]. We label the two possible target identities {g0 = S, g1 = H} and the possible ﬂanker identities
{c0 = S_S, c1 = H_H} with the underscore representing the position of the target. This gives us
the two congruent possibilities {[C = c0, G = g0], [C = c1, G = g1]} or [SSS,HHH] and the
two incongruent possibilities {[C = c0, G = g1], [C = c1, G = g0]} or [SHS,HSH]. The response
mapping function marginalize over context identities at each timestep:
c P (C = c, G = g0)
c P (C = c, G = g1)

r0 with probability (cid:80)
r1 with probability (cid:80)

r(P (C, G)) =

(cid:40)

(2)

The higher of the two response probabilities is compared to a threshold θ and when this threshold
is crossed, the model responds. What remains is to deﬁne the prior P0(C, G) and the likelihood
function P (eC, eG|C, G) or its inverse, the sample generation function. For sample generation, we
assume that the context and target are represented as two Gaussian distributions:

eC ∼ N (µc + αµµg , σ2
eG ∼ N (µg + αµµc, σ2

c + ασ σ2
g )
g + ασ σ2
c )

(3)

(4)
Here µc and µg are baseline means for the distributions of context and target, σ2
g are their
variances, and the α scaling factors mix them, potentially reﬂecting perceptual overlap in the sensors.
This formulation is a notational variant of an earlier ﬂanker model [5], but we are able to derive it by
describing the task in our formalism (we describe the exact mapping in the supplementary material).
Moreover, we later show how this notational equivalence lets us reproduce both Yu and colleagues’
results and data patterns in another task, using the same parameter settings.

c and σ2

3

4 Comparison to a constant-drift model

We now write the model in terms of a likelihood ratio test to facilitate comparison to Wald’s SPRT
and Wiener diffusion models. This is complementary to an earlier approach performing dynamical
analysis on the problem in probability space [22]. First we write the likelihood ratio Z of the full
response posteriors for the two responses. Since the likelihood ratio and the max a posteriori prob-
ability are monotonically related, thresholding on Z maps onto the threshold over the probability of
the most probable response we described above.

Z =

=

p(r(P (C, G)) = r0|eC , eG)
(cid:16)
(cid:17)
p(r(P (C, G)) = r1|eC , eG)
(cid:0)P (eC , eG | C = c0, G = g1)Pτ−1(C = c0, G = g1) + P (eC , eG | C = c1, G = g1)Pτ−1(C = c1, G = g1)(cid:1)
P (eC , eG | C = c0, G = g0)Pτ−1(C = c0, G = g0) + P (eC , eG | C = c1, G = g0)Pτ−1(C = c1, G = g0)

(5)

(6)

For this analysis we assume that context and target samples are drawn independently from each
other, i.e. that αµ = ασ = 0 and therefore that P (eC, eG | C, G) = P (eC | C)P (eG | T ). We also
index the evidence samples by time to remove the prior terms Pτ−1(·), and introduce the notation
| C = cx) for the likelihoods, with x ∈ {0, 1}
lt(tx) = P (eG
indexing stimuli and t ∈ {tcon = tgon . . . τ} indexing evidence samples over time. Now we can
t
rewrite:

| G = gx) and lt(cx) = P (eC

t

Zτ =

t lt(c0)lt(g0) + P0(C = c1, G = g0)(cid:81)
t lt(c0)lt(g1) + P0(C = c1, G = g1)(cid:81)

Divide both the numerator and the denominator by(cid:81)

=

P0(C = c0, G = g0)(cid:81)
P0(C = c0, G = g1)(cid:81)
P0(C = c0)P (G = g0 | C = c0)(cid:81)
P0(C = c0)P (G = g1 | C = c0)(cid:81)
P0(C = c0)P (G = g0 | C = c0)(cid:81)
P0(C = c0)P (G = g1 | C = c0)(cid:81)

Zτ =

Separate out the target likelihood product and take logs:

log Zτ =

τ(cid:88)

t=1

log

lt(g0)
lt(g1)

+ log

P (G = g0 | C = c0)
P (G = g1 | C = c0)

t lt(c1)lt(g0)
t lt(c1)lt(g1)

t

t

lt(c0 )

lt(c0 )

t lt(c1)lt(g0)
t lt(c1)lt(g1)

t lt(c1):

t lt(c0)lt(g0) + P0(C = c1)P (G = g0 | C = c1)(cid:81)
t lt(c0)lt(g1) + P0(C = c1)P (G = g1 | C = c1)(cid:81)
lt(c1 ) lt(g0) + P0(C = c1)P (G = g0 | C = c1)(cid:81)
lt(c1 ) lt(g1) + P0(C = c1)P (G = g1 | C = c1)(cid:81)
g =(cid:80)
g = (cid:80)

P0 (C=c0)
P0 (C=c1)
P0 (C=c0)
P0 (C=c1)

(cid:81)
(cid:81)

t

t

lt(c0 )

lt(c1 ) + P (G = g0 | C = c1)
lt(c1 ) + P (G = g1 | C = c1)

lt(c0 )

t lt(g0)

t lt(g1)

(7)

(8)

(9)

(10)

(11)

lt(g1). In the
Now, the ﬁrst term is the Wald’s sequential probability ratio test [7] with zτ
continuum limit, it is equal to a Wiener diffusion process dzg = agdt+bgdW with ag = E[log l(g0)
l(g1) ]
and b2
lt(g1) and do
the same for the context drift that appears on both numerator and denominator of the ﬁnal term:
zc

l(g1) ] [1, 4]. We can relabel the SPRT for the target zτ

g = Var[log l(g0)

t log lt(g0)

τ =(cid:80)

c = log P0(C=c0)

t log lt(c0)

t log lt(g0)

lt(c1) and z0

P0(C=c1). Then the expression is as follows:
c + P (G = g0 | C = c1)
c + P (G = g1 | C = c1)

P (G = g0 | C = c0)ez0
P (G = g1 | C = c0)ez0

c +zτ
c +zτ

log Zτ = zτ

g + log

(cid:17)

(cid:16) P (G=g0)

log Z τ in equation (11) comprises two terms. The ﬁrst is the unbiased SPRT statistic, while the
second is a nonlinear function of the SPRT statistic for the decision on the context. The nonlinear
term plays the role of bias in the SPRT for decision on target. This rational dynamic prior bias is an
advance over previous heuristic approaches to dynamic biases [e.g. 23].
Several limits of (11) are of interest: if the context and the target are independent, then the second
, and (11) reduces to the biased SPRT for the target. If each target
term reduces to log
is equally likely given a context, then the nonlinear term in (11) reduces to zero and (11) reduces
to the SPRT for the target. If each context deterministically determines a different target, then any
piece of evidence on the context is equally informative about the target. Accordingly, (11) reduces
to the sum of statistic for context and target, i.e., zτ
c ). If the magnitude of drift rate for
the context is much higher than the magnitude of drift rate for the target, or the magnitude of the
0 is high, then the nonlinear term saturates at a faster timescale compared to the decision time.
bias zc
In this limit, the approximate contribution of the nonlinear term is either log
, or

(cid:16) P (G=g0|C=c0)

g ± (zτ

c + z0

P (G=g1)

(cid:17)

P (G=g1|C=c0)

. Finally, in the limit of large thresholds, or equivalently, large decision times
log
|zc
c| will be small, and the nonlinear term in (11) can be approximated
τ + zc
by a linear function of zτ
0 obtained using the ﬁrst order Taylor series expansion. In all these
cases, (11) can be approximated by a sum of two SPRTs. However, this approximation may not hold

P (G=g1|C=c1)
0| will be a large, e−|zτ
c + zc

c +z0

(cid:16) P (G=g0|C=c1)

(cid:17)

4

in general and we suspect many interesting cases will require us to consider the nonlinear model
in (11). In those cases, the signal and noise characteristics of context and target will have different –
and we think distinguishable – effects on the RT distributions we measure.

5 The internal-context update and application to a new task

Recall our promise to explore two extremes on the dimension of context and onset timing, and
two extremes on the dimension of context-response dependence. The ﬂanker task is an external
context task with a context-independent response, so we now turn to an internal context task with
context-dependent response. This task is the AX Continuous Performance Test (AX-CPT), a task
with origins in the psychiatry literature now applied to cognitive control [6]. In this task, subjects
are asked to make a response to a probe (target) stimulus, by convention labeled ‘X’ or ‘Y’, where
the response mapping is determined by a previously seen cue (context) stimulus, ‘A’ or ‘B’. In our
notation: g0 = X, g1 = Y, c0 = A, c1 = B. Unlike the ﬂanker, where all stimuli pairs are equally
likely, in the AX-CPT AX trials are usually the most common (appearing 50% of the time or more),
and BY trials least common. AY and BX trials appear with equal frequency, but have dramatically
different conditional probabilities due to the preponderance of AX trials.
Two response mappings are used in the literature: an asymmetric one where one response is made
on AX trials and the other response otherwise; and a symmetric variant where one response is made
to AX and BY trials, and the other to AY and BX trials. We focus on the symmetric variant, since
in this case the response is always context-dependent (in the asymmetric variant the response is is
context-independent on Y trials). We can use the deﬁnition of the task to write a new form for r(·):

r(P (C, G)) =

r0 = ‘lef t(cid:48)
with probability P (G = g0, C = c0) + P (G = g1, C = c1)
r1 = ‘right(cid:48) with probability P (G = g0, C = c1) + P (G = g1, C = c0)

(12)

(cid:40)

We assume for simplicity that the inference process on the context models the maintenance of con-
text information and retrieval of the response rule (though the model could be extended to perceptual
, using the following
encoding of the context as well). That is, we start the inference machine at tof f
update when tof f

c ≤ τ ≤ ton
g :

c

Then, once the target appears the update becomes:

Pτ (C, G | eC ) ∝ P (eC | C, G)Pτ−1(C, G)

(13)

Pτ (C, G | eC , eG) ∝ P (eC , eG | C, G)Pτ−1(C, G)

(14)
For samples after the context disappears, we introduce a simple decay mechanism wherein the prob-
ability with which the context sensor provides a sample from the true context decays exponentially.
A sample is drawn from the true context with probability e−d(τ−tof f
), and drawn uniformly oth-
erwise. The update takes this into account, such that as τ grows the ratio P (eC|C=c0)
P (eC|C=c1) approaches
1 and the context sensor stops being informative (notation omitted for space). This means that the
unconditional posterior of context can saturate at values other than 1. The remainder of the model
is exactly as described above. This provides an opportunity to generate predictions of both tasks in
a shared model, something we take up in the ﬁnal portion of the paper. But ﬁrst, as in the ﬂanker
model, we reduce this model to a combination of multiple instances of the well-understood DDM.

c

6 Relating the internal context model to the ﬁxed-context drift model

We sketch an intuition for how our internal context model can be built up from a combination of
ﬁxed-context drift models (again assuming sensor independence). The derivation uses the same trick
of dividing numerator and denominator by the likelihood as the ﬂanker expressions, and is included
in the supplementary material, as is the asymmetric variant. We state the ﬁnal expression for the
symmetric case here:

log Z = log

P0(C = c0, G = g0)ezτ
c e
P0(C = c0, G = g1)ezτ

zτ
g + P0(C = c1, G = g1)
zτ
g

c + P0(C = c1, G = g0)e

(15)

Equation (15) combines the SPRT statistic associated with the context and the target in a nonlinear
fashion which is more complicated than in (11), further complicated by the fact that the memory
decay turns the context random walk into an Ornstein-Uhlenbeck process in expectation (notation
omitted for space, but follows from the relationship between continuous O-U and discrete AR(1)
processes). The reduction of these equations to a SPRT or the sum of two SPRTs is subtle, and is
valid only in rather contrived settings. For example, if the drift rate for the target is much higher

5

than the drift rate for the context, then in the limit of large thresholds (15) can be approximated by
either log P0(C=c0,G=g0)
c . As with (11), we think it will be highly
instructive to further invesgate the cases where the reductions cannot apply.

P0(C=c0,G=g1) − zτ

c , or log P0(C=c1,G=g1)

P0(C=c1,G=g0) + zτ

7 Simulation results for both tasks using the same model and parameters

With the relationship between both tasks established via our theory, we can now simulate behavior in
both tasks under nearly the same model parameters. The one difference is in the memory component,
governed by the memory decay parameter d and the target onset time τton. Longer intervals between
context disappearance and target appearance have the same effect as higher values of d: they make
context retrieved more poorly. We use d = 0.0001 for the decay and a 2000-timestep interval, which
results in approximately 82% probability of drawing a correct sample by the time the target comes
on. The effect of both parameters is equivalent in the results we show, since we do not explore
variable context-target delays, but could be explored by varying this duration.
For simplicity we assume the sampling distribution for eC and eG is identical for both tasks, though
this need not hold except for identical stimuli sampled from perception. For ﬂanker simulations we
use the model no spatial uncertainty, i.e. αµ = ασ = 0, to best match the AX-CPT model and
our analytical connections to the SPRT. We assume the model has a high congruence prior for the
ﬂanker model, and the correct prior for the AX-CPT, as detailed in Table 1.

Context

Target

Prior

Flanker AX-CPT Flanker AX-CPT Flanker AX-CPT
S_S
S_S
H_H
H_H

0.45
0.05
0.05
0.45

0.5
0.2
0.2
0.1

A
A
B
B

S
H
S
H

X
Y
X
Y

Table 1: Priors for the inference process for the Flanker and AX-CPT instantiation of our theory.

The remainder of parameters are identical across both task simulations: σc = σg = 9, θ = 0.9,
µc = µg = 0 for c0 and g0, and µc = µg = 1 for c1 and g1. To replicate the ﬂanker results,
we followed [5] by introducing a non-decision error parameter γ = 0.03: this is the probability of
making a random response immediately at the ﬁrst timestep. We simulated 100,000 trials for each
model. Figure 1 shows results from the simulation of the ﬂanker task, recovering the characteristic
early below-chance performance in incongruent trials. This simulation supports the assertion that
our theory generalizes the ﬂanker model of [5], though we are not sure why our scale on timesteps
appears different by about 5x in spite of using what we think are equivalent parameters. A library
for simulating tasks that ﬁt in our framework and code for generating all simulation ﬁgures in this
paper can be found at https://github.com/mshvartsman/cddm.
For the AX-CPT behavior, we compare qualitative patterns from our model to a heterogeneous
dataset of humans performing this task (n=59) across 4 different manipulations with 200 trials per
subject [24]. The manipulations were different variants of “proactive”-behavior inducing manipu-
lations in the sense of [25]. This is the most apt comparison to our model: proactive strategies are
argued to involve response preparation of the sort that our model reﬂects in its accumulation over
the context before the target appears.
Figure 2 shows mean RTs and accuracies produced by our model for the AX-CPT, under the same
parameters that we used for the ﬂanker model. This model recovers the qualitative pattern of behav-
ior seen in human subjects in this task, both RT and error proportion by condition showing the same
pattern. Moreover, if we examine the conditional RT plot (Figure 3) we see that the model predicts
a region of below-chance performance early in AY trials but not other trials. This effect appears
isomorphic to the early congruence effect in the ﬂanker task, in the sense that both are caused by a
strong prior biased away from the correct response: on incongruent trials given a high congruence
prior in the ﬂanker, and on AY trials given a high AX prior in AX-CPT. More generally, the model
recovers conditional accuracy curves that look very similar to those in the human data.

6

Figure 1: Model recovers characteristic ﬂanker pattern. Left: response time computed by 50-
timestep RT bin for congruent and incongruent trials, showing early below-chance performance.
Right: response time distributions for congruent and incongruent trials, showing the same mode but
fatter tail for incongruent relative to congruent trials. Both are signature phenomena in the ﬂanker
task previously recovered by the model of Yu and colleagues, consistent with our theory being a
generalization of their model.

Figure 2: Model recovers gross RT patterns in human behavior. Left: RT and error rates by trial
type in the model, using the same parameters as the ﬂanker model. Right: RT and error rates by trial
type in 59 human participants. Error bars are standard errors (where not visible, they are smaller
than the dots). Both RT and error patterns are quite similar (note that the timestep-to-ms mapping
need not be one-to-one).

8 Discussion

In this paper, we have provided a theoretical framework for understanding decision making under
dynamically shifting context. We used this framework to derive models of two distinct tasks from
the cognitive control literature, one a notational equivalent of a previous model and the other a novel
model of a well-established task. We showed how we can write these models in terms of com-
binations of constant-drift random walks. Most importantly, we showed how two models derived
from our theoretical framing can recover RT, error, and RT-conditional accuracy patterns seen in
human data without a change of parameters between tasks and task models. Our results are quan-
titatively robust to small changes in the prior because equations 12 and 16 are smooth functions of
the prior. The early incongruent errors in ﬂanker are also robust to larger changes, as long as the
congruence prior is above 0.5. The ordering of RTs and error rates for AX-CPT rely on assuming
that participants at least learn the correct ordering of trial frequencies – we think an uncontroversial
assumption.
One natural next step should be to generate direct quantitative predictions of behavior in one task
based on a model trained on another task – ideally on an individual subject level, and in a task

7

llllllllllllllllllllllllllllllllllllllllll0.000.250.500.751.0002505007501000TimestepsAccuracyllCongruentIncongruent0.0000.0020.0040.00602505007501000TimestepsdensityCongruentIncongruentllll350400450500550A:XA:YB:XB:YTrial TypeRT (timesteps)RT by condition (model)llll0.050.100.150.20A:XA:YB:XB:YTrial TypeError ProportionErrors by condition (model)llll420430440450460470AXAYBXBYTrial TypeRT (ms)RT by condition (humans)llll0.050.100.150.20AXAYBXBYTrial TypeError ProportionErrors by condition (humans)Figure 3: Model recovers conditional accuracy pattern in human behavior. Left: response
time computed by 50-timestep bin for the four trial types, using same parameters as the ﬂanker
model. Right: same plot from 59 human participants (see text for details). Bins with fewer than
50 observations omitted. Error bars are standard errors (where not visible, they are smaller than
the dots). Both plots show qualitatively similar patterns. Two discrepancies are of note: ﬁrst, the
model predicts very early AY responses to be more accurate than slightly later responses, and early
B responses to be close to chance. We think at least part of this is due to the non-decision error γ,
but we retained it for consistency with the ﬂanker model. Second, the humans show slightly better
BY than BX performance early on, something the model does not recover. We think this may have
to do with a global left-response bias that the model is somehow not capturing. Note: the abscissae
are in different units (though they correspond surprisingly well).

that ﬁts in our framework that has not been extensively explored (for example, an internal-context
Flanker variant, or a context-dependent response congruence judgment task). The main challenge in
pursuing this kind of analysis is our ability to efﬁciently estimate and explore these models which,
unlike the ﬁxed-context models, have no closed-form analytic expressions or fast approximations.
We believe that approximations such as those provided for the ﬂanker model [22] can and should
be applied within our framework, both as a way to generate more efﬁcient data ﬁts, and as a way
to apply the tools of dynamical systems analysis to the overall behavior of a system. Of particu-
lar interest is whether some points in the task space deﬁned in our framework map onto existing
descriptive decision models [e.g. 3].
Another natural next step is to seek evidence of our proposed form of integrator in neural data,
or investigate plausible neural implementations or approximations to it. One way of doing so is
computing time-varying tuning curves of neural populations in different regions to the individual
components of the accumulators we propose in equations (11) and (15). Another is to ﬁnd connec-
tivity patterns that perform the log-sum computation we hypothesize happens in the integrator. A
third is to look for components correlated with them in EEG data. All of these methods have some
promise, as they have been successfully applied to the ﬁxed context model [9, 10, 26]. Such neural
data would not only test a prediction of our theory, but also – via the brain locations found to be
correlated – address questions we presently do not address, such as whether the dynamic weighting
happens at the sampler or further upstream (i.e. whether unreliable evidence is gated at the sampler
or discounted at the integrator).
A second key challenge given our focus on optimal inference is the fact that the ﬁxed threshold
decision rule we use is suboptimal for the case of non identically distributed observations. While
the likelihoods of context and target are independent in our simulations, the likelihoods of the two
responses are not identically distributed. The optimal threshold is generally time-varying for this
case [27], though the speciﬁc form is not known.
Finally, while our model recovers RT-conditional accuracies and stimulus-conditional RT and accu-
racy patterns, it fails to recover the correct pattern of accuracy-conditional RTs. That is, it predicts
much faster errors than corrects on average. Future work will need to investigate whether this is
caused by qualitative or quantitative aspects of the theoretical framework and model.

References
[1] D. R. J. Laming, Information theory of choice-reaction times. London: Academic Press, 1968.

[2] R. Ratcliff, “A theory of memory retrieval.,” Psychological Review, vol. 85, no. 2, pp. 59–108, 1978.

8

0.000.250.500.751.0002505007501000TimestepsAccuracyA:XA:YB:XB:YConditional Accuracy (model)0.000.250.500.751.0002505007501000RT (ms)AccuracyAXAYBXBYConditional Accuracy (humans)[3] M. Usher and J. L. McClelland, “The time course of perceptual choice: The leaky, competing accumulator

model.,” Psychological Review, vol. 108, no. 3, pp. 550–592, 2001.

[4] R. Bogacz, E. Brown, J. Moehlis, P. Holmes, and J. D. Cohen, “The physics of optimal decision making: a
formal analysis of models of performance in two-alternative forced-choice tasks.,” Psychological review,
vol. 113, pp. 700–65, Oct. 2006.

[5] A. J. Yu, P. Dayan, and J. D. Cohen, “Dynamics of attentional selection under conﬂict: toward a rational
Bayesian account.,” Journal of experimental psychology. Human perception and performance, vol. 35,
pp. 700–17, June 2009.

[6] D. Servan-Schreiber, J. D. Cohen, and S. Steingard, “Schizophrenic Deﬁcits in the Processing of Context,”

Archives of General Psychiatry, vol. 53, p. 1105, Dec. 1996.

[7] A. Wald and J. Wolfowitz, “Optimum Character of the Sequential Probability Ratio Test,” The Annals of

Mathematical Statistics, vol. 19, pp. 326–339, Sept. 1948.

[8] S. Kira, T. Yang, and M. N. Shadlen, “A Neural Implementation of Wald’s Sequential Probability Ratio

Test,” Neuron, vol. 85, pp. 861–873, Feb. 2015.

[9] R. Bogacz and K. N. Gurney, “The basal ganglia and cortex implement optimal decision making between

alternative actions.,” Neural computation, vol. 19, pp. 442–77, Feb. 2007.

[10] M. K. van Vugt, P. Simen, L. E. Nystrom, P. Holmes, and J. D. Cohen, “EEG oscillations reveal neural

correlates of evidence accumulation.,” Frontiers in neuroscience, vol. 6, p. 106, Jan. 2012.

[11] B. M. Turner, L. van Maanen, and B. U. Forstmann, “Informing cognitive abstractions through neu-
roimaging: The neural drift diffusion model.,” Psychological Review, vol. 122, no. 2, pp. 312–336, 2015.
[12] D. Norris, “The Bayesian reader: explaining word recognition as an optimal Bayesian decision process.,”

Psychological review, vol. 113, pp. 327–357, Apr. 2006.

[13] K.-F. Wong and X.-J. Wang, “A recurrent network mechanism of time integration in perceptual deci-
sions.,” The Journal of neuroscience : the ofﬁcial journal of the Society for Neuroscience, vol. 26, no. 4,
pp. 1314–1328, 2006.

[14] P. I. Frazier and A. J. Yu, “Sequential hypothesis testing under stochastic deadlines,” Advances in Neural

Information Processing Systems, pp. 1–8, 2008.

[15] J. Drugowitsch, R. Moreno-Bote, A. K. Churchland, M. N. Shadlen, and A. Pouget, “The cost of accu-
mulating evidence in perceptual decision making.,” The Journal of Neuroscience, vol. 32, pp. 3612–28,
Mar. 2012.

[16] N. Srivastava and P. Schrater, “Rational inference of relative preferences,” in Advances in Neural Infor-

mation Processing Systems 25, pp. 2312–2320, 2012.

[17] R. C. O’Reilly and M. J. Frank, “Making Working Memory Work: A Computational Model of Learning

in the Prefrontal Cortex and Basal Ganglia,” Neural Computation, vol. 18, pp. 283–328, Feb. 2006.

[18] J. P. Sheppard, D. Raposo, and A. K. Churchland, “Dynamic weighting of multisensory stimuli shapes

decision-making in rats and humans.,” Journal of vision, vol. 13, no. 6, pp. 1–19, 2013.

[19] J. R. Stroop, “Studies of interference in serial verbal reactions.,” Journal of Experimental Psychology,

vol. 18, no. 6, pp. 643–662, 1935.

[20] G. Gratton, M. G. Coles, E. J. Sirevaag, C. W. Eriksen, and E. Donchin, “Pre- and poststimulus activa-
tion of response channels: a psychophysiological analysis.,” Journal of experimental psychology. Human
perception and performance, vol. 14, no. 3, pp. 331–344, 1988.

[21] J. R. Simon and J. D. Wolf, “Choice reaction time as a function of angular stimulus-response correspon-

dence and age,” Ergonomics, vol. 6, pp. 99–105, Jan. 1963.

[22] Y. S. Liu, A. Yu, and P. Holmes, “Dynamical analysis of Bayesian inference models for the Eriksen task.,”

Neural computation, vol. 21, pp. 1520–53, June 2009.

[23] T. D. Hanks, M. E. Mazurek, R. Kiani, E. Hopp, and M. N. Shadlen, “Elapsed decision time affects
the weighting of prior probability in a perceptual decision task.,” The Journal of Neuroscience, vol. 31,
pp. 6339–52, Apr. 2011.

[24] O. Lositsky, R. C. Wilson, M. Shvartsman, and J. D. Cohen, “A Drift Diffusion Model of Proactive and
Reactive Control in a Context-Dependent Two-Alternative Forced Choice Task,” in The Multi-disciplinary
Conference on Reinforcement Learning and Decision Making, pp. 103–107, 2015.

[25] T. S. Braver, “The variable nature of cognitive control: a dual mechanisms framework.,” Trends in cogni-

tive sciences, vol. 16, pp. 106–13, Feb. 2012.

[26] T. D. Hanks, C. D. Kopec, B. W. Brunton, C. A. Duan, J. C. Erlich, and C. D. Brody, “Distinct relation-

ships of parietal and prefrontal cortices to evidence accumulation,” Nature, 2015.

[27] Y. Liu and S. Blostein, “Optimality of the sequential probability ratio test for nonstationary observations,”

IEEE Transactions on Information Theory, vol. 38, no. 1, pp. 177–182, 1992.

9

