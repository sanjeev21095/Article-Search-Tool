Scalable Adaptation of State Complexity for

Nonparametric Hidden Markov Models

Michael C. Hughes, William Stephenson, and Erik B. Sudderth

Department of Computer Science, Brown University, Providence, RI 02912

mhughes@cs.brown.edu, wtstephe@gmail.com, sudderth@cs.brown.edu

Abstract

Bayesian nonparametric hidden Markov models are typically learned via ﬁxed
truncations of the inﬁnite state space or local Monte Carlo proposals that make
small changes to the state space. We develop an inference algorithm for the sticky
hierarchical Dirichlet process hidden Markov model that scales to big datasets by
processing a few sequences at a time yet allows rapid adaptation of the state space
cardinality. Unlike previous point-estimate methods, our novel variational bound
penalizes redundant or irrelevant states and thus enables optimization of the state
space. Our birth proposals use observed data statistics to create useful new states
that escape local optima. Merge and delete proposals remove ineffective states to
yield simpler models with more affordable future computations. Experiments on
speaker diarization, motion capture, and epigenetic chromatin datasets discover
models that are more compact, more interpretable, and better aligned to ground
truth segmentations than competitors. We have released an open-source Python
implementation which can parallelize local inference steps across sequences.

1 Introduction

The hidden Markov model (HMM) [1, 2] is widely used to segment sequential data into interpretable
discrete states. Human activity streams might use walking or dancing states, while DNA transcrip-
tion might be understood via promotor or repressor states [3]. The hierarchical Dirichlet process
HMM (HDP-HMM) [4, 5, 6] provides an elegant Bayesian nonparametric framework for reasoning
about possible data segmentations with different numbers of states.

Existing inference algorithms for HMMs and HDP-HMMs have numerous shortcomings: they can-
not efﬁciently learn from large datasets, do not effectively explore segmentations with varying num-
bers of states, and are often trapped at local optima near their initialization. Stochastic optimization
methods [7, 8] are particularly vulnerable to these last two issues, since they cannot change the num-
ber of states instantiated during execution. The importance of removing irrelevant states has been
long recognized [9]. Samplers that add or remove states via split and merge moves have been de-
veloped for HDP topic models [10, 11] and beta process HMMs [12]. However, these Monte Carlo
proposals use the entire dataset and require all sequences to ﬁt in memory, limiting scalability.

We propose an HDP-HMM learning algorithm that reliably transforms an uninformative, single-state
initialization into an accurate yet compact set of states. Generalizing previous work on memoized
variational inference for DP mixture models [13] and HDP topic models [14], we derive a variational
bound for the HDP-HMM that accounts for sticky state persistence and can be used for effective
Bayesian model selection. Our algorithm uses birth proposal moves to create new states and merge
and delete moves to remove states with poor predictive power. State space adaptations are validated
via a global variational bound, but by caching sufﬁcient statistics our memoized algorithm efﬁciently
processes subsets of sequences at each step. Extensive experiments demonstrate the reliability and
scalability of our approach, which can be reproduced via Python code we have released online1.

1http://bitbucket.org/michaelchughes/x-hdphmm-nips2015/

1

(A) Initialization, K=1 

(B) After first lap births, K=47 

(C) After first lap merges, K=37 

!

"!!

#!!

$!!

%!!

!

"!!

#!!

$!!

%!!

!

"!!

#!!

$!!
$!!

%!!
%!!

accepted merge pairs 

(F) Ground truth labels, K=12 

(E) After 100 laps, K=31 

(D) After second lap, K=56 

accepted birth 

#!!

$!!

!

$!!

%!!

"!!

#!!

"!!

%!!

!
Figure 1: Illustration of our new birth/merge/delete variational algorithm as it learns to segment motion capture
sequences into common exercise types (Sec. 5). Each panel shows segmentations of the same 6 sequences,
with time on the horizontal axis. Starting from just one state (A), birth moves at the ﬁrst sequence create useful
states. Local updates to each sequence in turn can use existing states or birth new ones (B). After all sequences
are updated once, we perform merge moves to clean up and lap is complete (C). After another complete lap of
birth updates at each sequence followed by merges and deletes, the segmentation is further reﬁned (D). After
many laps, our ﬁnal segmentation (E) aligns well to labels from a human annotator (F), with some true states
aligning to multiple learned states that capture subject-speciﬁc variability in exercises.

"!!

#!!

$!!

%!!

!

2 Hierarchical Dirichlet Process Hidden Markov Models

. . . , xnTn ] and
We wish to jointly model N sequences, where sequence n has data xn = [xn1, xn2,
observation xnt is a vector representing interval or timestep t. For example, xnt ∈ RD could be the
spectrogram for an instant of audio, or human limb positions during a 100ms interval.

The HDP-HMM explains this data by assigning each observation xnt to a single hidden state znt.
The chosen state comes from a countably inﬁnite set of options k ∈ {1, 2, . . .}, generated via
Markovian dynamics with initial state distributions π0 and transition distributions {πk}∞

k=1:

p(zn1 = k) = π0k,

p(znt = ℓ | zn,t−1 = k) = πkℓ.

(1)

We draw data xnt given assigned state znt = k from an exponential family likelihood F :

F : log p(xnt | φk) = sF (xdn)T φk + cF (φk),

H : log p(φk | ¯τ ) = φT

k ¯τ + cH (¯τ ).

(2)

The natural parameter φk for each state has conjugate prior H. Cumulant functions cF , cH ensure
these distributions are normalized. The chosen exponential family is deﬁned by its sufﬁcient statis-
tics sF . Our experiments consider Bernoulli, Gaussian, and auto-regressive Gaussian likelihoods.

Hierarchies of Dirichlet processes. Under the HDP-HMM prior and posterior, the number of
states is unbounded; it is possible that every observation comes from a unique state. The hierarchical
Dirichlet process (HDP) [5] encourages sharing states over time via a latent root probability vector
β over the inﬁnite set of states (see Fig. 2). The stick-breaking representation of the prior on β ﬁrst
ℓ=1 (1 − uℓ).
We interpret uk as the conditional probability of choosing state k among states {k, k + 1, k + 2, . . .}.

draws independent variables uk ∼ Beta(1, γ) for each state k, and then sets βk = ukQk−1
probabilities via the vector [β1 β2 . . . βK β>K], where β>K = P∞

In expectation, the K most common states are ﬁrst in stick-breaking order. We represent their
k=K+1 βk. Given this (K + 1)-
dimensional probability vector β, the HDP-HMM generates transition distributions πk for each state
k from a Dirichlet with mean equal to β and variance governed by concentration parameter α > 0:

[πk1 . . . πkK πk>K] ∼ Dir(αβ1, αβ2, . . . , αβ>K).

(3)

We draw starting probability vector π0 from a similar prior with much smaller variance, π0 ∼
Dir(α0β) with α0 ≫ α, because few starting states are observed.

Sticky self-transition bias.
In many applications, we expect each segment to persist for many
timesteps. The “sticky” parameterization of [4, 6] favors self-transition by placing extra prior mass
on the transition probability πkk. In particular, [πk1 . . . πk>K] ∼ Dir(αβ1, . . . αβk + κ, . . . αβ>K)
where κ > 0 controls the degree of self-transition bias. Choosing κ ≈ 100 leads to long segment
lengths, while avoiding the computational cost of semi-Markov alternatives [7].

2

uk

ˆρk
ˆωk

∞

πk

ˆθk

∞

ˆsn1

zn1

ˆsn2 ˆsnT -1

zn2

· · ·

znT

φk

ˆτk

∞

−50

−100

−150

cD sticky

lower bound

−20

−40

−60

−80

−100

−120
0

cD sticky

lower bound

5

15

10
20
num states K

25

30

xn1

xn2 · · ·

−200

0.0

xnT

N

0.5

1.0

1.5

2.0

alpha

Figure 2: Left: Graphical representation of the HDP hidden Markov model. Variational parameters are shown
in red. Center: Our surrogate bound for the sticky Dirichlet cumulant function cD (Eq. 9) as a function of α,
computed with κ = 100 and uniform β with K = 20 active states. Right: Surrogate bound vs. K, with ﬁxed
κ = 100, α = 0.5. This bound remains tight when our state adaptation moves insert or remove states.

3 Memoized and Stochastic Variational Inference

After observing data x, our inferential goal is posterior knowledge of top-level conditional probabil-
ities u, HMM parameters π, φ, and assignments z. We refer to u, π, φ as global parameters because
they generalize to new data sequences. In contrast, the states zn are local to a speciﬁc sequence xn.

3.1 A Factorized Variational Lower Bound

We seek a distribution q over the unobserved variables that is close to the true posterior, but lies in the
simpler factorized family q(·) , q(u)q(φ)q(π)q(z). Each factor has exponential family form with
free parameters denoted by hats, and our inference algorithms update these parameters to minimize
the Kullback-Leibler (KL) divergence KL(q || p). Our chosen factorization for q is similar to [7],
but includes a substantially more accurate approximation to q(u) as detailed in Sec. 3.2.

Factor q(z). For each sequence n, we use an independent factor q(zn) with Markovian structure:

q(zn) ," K
Yk=1

ˆrδk(zn1)
n1k

# T −1
Yt=1

K

Yk=1

K

Yℓ=1(cid:20) ˆsntkℓ

ˆrntk (cid:21)δk(znt)δℓ(zn,t+1)

(4)

Free parameter vector ˆsnt deﬁnes the joint assignment probabilities ˆsntkℓ , q(zn,t+1 = ℓ, znt = k),
so the K 2 non-negative entries of ˆsnt sum to one. The parameter ˆrnt deﬁnes the marginal probability
ℓ=1 ˆsntkℓ. We can ﬁnd the expected count of transitions

ˆrntk = q(znt = k), and equals ˆrntk = PK
from state k to ℓ across all sequences via the sufﬁcient statistic Mkℓ(ˆs) ,PN

The truncation level K limits the total number of states to which data is assigned. Under our approx-
imate posterior, only q(zn) is constrained by this choice; no global factors are truncated. Indeed, if
data is only assigned to the ﬁrst K states, the conditional independence properties of the HDP-HMM
imply that {φk, uk | k > K} are independent of the data. Their optimal variational posteriors thus
match the prior, and need not be explicitly computed or stored [15, 16]. Simple variational algo-
rithms treat K as a ﬁxed constant [7], but Sec. 4 develops novel algorithms that ﬁt K to data.

n=1PTn−1

t=1 ˆsntkℓ.

Factor q(π). For the starting state (k = 0) and each state k ∈ 1, 2, . . ., we deﬁne q(πk) as a
Dirichlet distribution: q(πk) , Dir(ˆθk1, . . . , ˆθkK , ˆθk>K). Free parameter ˆθk is a vector of K + 1
positive numbers, with one entry for each of the K active states and a ﬁnal entry for the aggregate
mass of all other states. The expected log transition probability between states k and ℓ, Pkℓ(ˆθ) ,

Eq[log πkℓ] = ψ(ˆθkℓ) − ψ(PK+1

m=1

ˆθkm), is a key sufﬁcient statistic.

Factor q(φ). Emission parameter φk for state k has factor q(φk) , H(ˆτk) conjugate to the likeli-
hood F . The supplement provides details for Bernoulli, Gaussian, and auto-regressive F .

We score the approximation q via an objective function L that assigns a scalar value (higher is better)
to each possible input of free parameters, data x, and hyperparameters γ, α, κ, ¯τ :

L(·) , Eq [log p(x, z, π, u, φ) − log q(z, π, u, φ)] = Ldata + Lentropy + Lhdp-local + Lhdp-global.

(5)

3

This function provides a lower bound on the marginal evidence: log p(x|γ, α, κ, ¯τ ) ≥ L. Improving
this bound is equivalent to minimizing KL(q || p). Its four component terms are deﬁned as follows:

q(φ)i ,
Ldata(x, ˆr, ˆτ ) , Eqhlog p(x | z, φ) + log p(φ)
Lhdp-local(ˆs, ˆθ, ˆρ, ˆω) , Eqhlog p(z | π) + log p(π)
q(π)i ,

Lentropy(ˆs) , −Eq [log q(z)] ,

q(u)i .
Lhdp-global(ˆρ, ˆω) , Eqhlog p(u)

(6)

Detailed analytic expansions for each term are available in the supplement.

3.2 Tractable Posterior Inference for Global State Probabilities

Previous variational methods for the HDP-HMM [7], and for HDP topic models [16] and HDP
grammars [17], used a zero-variance point estimate for the top-level state probabilities β. While
this approximation simpliﬁes inference, the variational objective no longer bounds the marginal evi-
dence. Such pseudo-bounds are unsuitable for model selection and can favor models with redundant
states that do not explain any data, but nevertheless increase computational and storage costs [14].

Because we seek to learn compact and interpretable models, and automatically adapt the truncation
level K to each dataset, we instead place a proper beta distribution on uk, k ∈ 1, 2, . . . K:

q(uk) , Beta(ˆρk ˆωk, (1−ˆρk)ˆωk), where ˆρk ∈ (0, 1), ˆωk > 0.

(7)

Here ˆρk = E
controls the variance, where the zero-variance point estimate is recovered as ˆωk → ∞.

q(u)[βk] = ˆρkE[β>k−1], and E

q(u)[uk], E

ℓ=1(1−ˆρℓ). The scalar ˆωk

q(u)[β>k] = Qk

The beta factorization in Eq. (7) complicates evaluation of the marginal likelihood bound in Eq. (6):

Lhdp-local(ˆs, ˆθ, ˆρ, ˆω) = E

E

q(u)[cD(αβ + κδk)]

k=1

q(u)[cD(α0β)] +PK
k=0PK+1
k=0 cD(ˆθk) +PK
−PK
cD(αβ) , log Γ(α) −PK+1

(8)
The Dirichlet cumulant function cD maps K +1 positive parameters to a log-normalization constant.
For a non-sticky HDP-HMM where κ = 0, previous work [14] established the following bound:

ℓ=1 (Mkℓ(ˆs) + αk E

q(u)[βℓ] + κδk(ℓ) − ˆθkℓ)Pkℓ(ˆθ).

Direct evaluation of E
have no closed form, but the lower bound has a simple expectation given beta distributed q(uk).

(9)
q(u)[cD(αβ)] is problematic because the expectations of log-gamma functions

k=1 log Γ(αβk) ≥ K log α +PK+1

ℓ=1 log βℓ.

Developing a similar bound for sticky models with κ > 0 requires a novel contribution. To begin,
in the supplement we establish the following bound for any κ > 0, α > 0:

cD(αβ + κδk) ≥ K log α − log(α + κ) + log(αβk + κ) +PK+1

q(u)[log(αβk + κ)], we leverage the concavity of the logarithm:

ℓ=1 ℓ6=k log(βℓ).

To handle the intractable term E

(10)

log(αβk + κ) ≥ βk log(α + κ) + (1 − βk) log κ.

(11)
Combining Eqs. (10) and (11) and taking expectations, we can evaluate a lower bound on Eq. (8) in
closed form, and thereby efﬁciently optimize its parameters. As illustrated in Fig. 2, this rigorous
lower bound on the marginal evidence log p(x) is quite accurate for practical hyperparameters.

3.3 Batch and Stochastic Variational Inference

Most variational inference algorithms maximize L via coordinate ascent optimization, where the
best value of each parameter is found given ﬁxed values for other variational factors. For the HDP-
HMM this leads to the following updates, which when iterated converge to some local maximum.

Local update to q(zn). The assignments for each sequence zn can be updated independently via
dynamic programming [18]. The forward-backward algorithm takes as input a Tn × K matrix of
log-likelihoods Eq[log p(xn | φk)] given the current ˆτ , and log transition probabilities Pjk given the
current ˆθ. It outputs the optimal marginal state probabilities ˆsn, ˆrn under objective L. This step has
cost O(TnK 2) for sequence n, and we can process multiple sequences in parallel for efﬁciency.

Global update to q(φ). Conjugate priors lead to simple closed-form updates ˆτk = ¯τ + Sk, where

sufﬁcient statistic Sk summarizes the data assigned to state k: Sk ,PN

Global update to q(π). For each state k ∈ {0, 1, 2 . . . K}, the positive vector ˆθk deﬁning the
optimal Dirichlet posterior on transition probabilities from state k is ˆθkℓ = Mkℓ(ˆs) + αβℓ + κδk(ℓ).
Statistic Mkℓ(ˆs) counts the expected number of transitions from state k to ℓ across all sequences.

n=1PTn

t=1 ˆrntksF (xnt).

4

Global update to q(u). Due to non-conjugacy, our surrogate objective L has no closed-form up-
date to q(u). Instead, we employ numerical optimization to update vectors ˆρ, ˆω simultaneously:

arg max

Lhdp-local(ˆρ, ˆω, ˆθ, ˆs) + Lhdp-global(ˆρ, ˆω)

subject to ˆωk > 0, ˆρk ∈ (0, 1) for k = 1, 2 . . . K.

ˆρ,ˆω

Details are in the supplement. The update to q(u) requires expectations under q(π), and vice versa,
so it can be useful to iteratively optimize q(π) and q(u) several times given ﬁxed local statistics.

To handle large datasets, we can adapt these updates to perform stochastic variational inference
(SVI) [19]. Stochastic algorithms perform local updates on random subsets of sequences (batches),
and then perturb global parameters by following a noisy estimate of the natural gradient, which
has a simple closed form. SVI has previously been applied to non-sticky HDP-HMMs with point-
estimated β [7], and can be easily adapted to our more principled objective. One drawback of SVI
is the requirement of a learning rate schedule, which must typically be tuned to each dataset.

3.4 Memoized Variational Inference

We now outline a memoized algorithm [13] for our sticky HDP-HMM variational objective. Before
execution, each sequence is randomly assigned to one of B batches. The algorithm repeatedly visits
batches one at a time in random order; we call each full pass through the complete set of B batches a
lap. At each visit to batch b, we perform a local step for all sequences n in batch b and then a global
step. With B = 1 batches, memoized inference reduces to the standard full-dataset algorithm, while
with larger B we have more affordable local steps and faster overall convergence. With just one lap,
memoized inference is equivalent to the synchronous version of streaming variational inference,
presented in Alg. 3 of Broderick et al. [20]. We focus on regimes where dozens of laps are feasible,
which we demonstrate dramatically improves performance.

M ,PB

Affordable, but exact, batch optimization of L is possible by exploiting the additivity of statistics
M , S. For each statistic we track a batch-speciﬁc quantity M b, and a whole-dataset summary
b=1 M b. After a local step at batch b yields ˆsb, ˆrb, we update M b(ˆsb) and Sb(ˆrb), increment
each whole-dataset statistic by adding the new batch summary and subtracting the summary stored
in memory from the previous visit, and store (or memoize) the new statistics for future iterations.
This update cycle makes M and S consistent with the most recent assignments for all sequences.
Memoization does require O(BK 2) more storage than SVI. However, this cost does not scale with
the number of sequences N or length T . Sparsity in transition counts M may make storage cheaper.

At any point during memoized execution, we can evaluate L exactly for all data seen thus far. This
is possible because nearly all terms in Eq. (6) are functions of only global parameters ˆρ, ˆω, ˆθ, ˆτ
and sufﬁcient statistics M, S. The one exception that requires local values ˆs, ˆr is the entropy term
Lentropy. To compute it, we track a (K + 1) × K matrix H b at each batch b:

,

(12)

ℓ=1 Hkℓ.

where the sums aggregate sequences n that belong to batch b. Each entry of H b is non-negative, and

H b

0ℓ = −Pn ˆrn1ℓ log ˆrn1ℓ, H b
given the whole-dataset entropy matrix H =PB

t=1 ˆsntkℓ log ˆsntkℓ
ˆrntk

kℓ = −PnPTn−1
b=1 H b, we have Lentropy =PK

k=0PK

4 State Space Adaptation via Birth, Merge, and Delete Proposals

Reliable nonparametric inference algorithms must quickly identify and create missing states. Split-
merge samplers for HDP topic models [10, 11] are limited because proposals can only split an
existing state into two new states, require expensive traversal of all data points to evaluate an ac-
ceptance ratio, and often have low acceptance rates [12]. Some variational methods for HDP topic
models also dynamically create new topics [16, 21], but do not guarantee improvement of the global
objective and can be unstable. We instead interleave stochastic birth proposals with delete and merge
proposals, and use memoization to efﬁciently verify proposals via the exact full-dataset objective.

Birth proposals. Birth moves can create many new states at once while maintaining the monotonic
increase of the whole-dataset objective, L. Each proposal happens within the local step by trying
to improve q(zn) for a single sequence n. Given current assignments ˆsn, ˆrn with truncation K, the
move proposes new assignments ˆs′
n that include the K existing states and some new states with
index k > K. If L improves under the proposal, we accept and use the expanded set of states for
all remaining updates in the current lap. To compute L, we require candidate global parameters
ˆρ′, ˆω′, ˆθ′, ˆτ ′. These are found via a global step from candidate summaries M ′, S′, which combine

n, ˆr′

5

30

15

0

−15

−30

K
 
s
c
p
o

i

t
 

m
u
n

50

25

*8

−30 −15 0

15 30

10

100 1000
1
num pass thru data

i

.
t
s
d
 
g
n
m
m
a
H

i

0.8

0.6

0.4

0.2

0.0

10

100 1000
1
num pass thru data

sampler
stoch
memo
delete,merge
birth,delete,merge
Non-stick, kappa=0
Sticky, kappa=50

stoch:  K=47 after 2000 laps in 359 min.

sampler:  K=10 after 2000 laps in 74 min.

delete,merge:  K=8 after 100 laps in 5 min.

0

200

400

600

800

0

200

400

600

800

0

200

400

600

800

Figure 3: Toy data experiments (Sec. 5). Top left: Data sequences contain 2D points from 8 well-separated
Gaussians with sticky transitions. Top center: Trace plots from initialization with 50 redundant states. Our
state-adaptation algorithms (red/purple) reach ideal K = 8 states and zero Hamming distance regardless of
whether a sticky (solid) or non-sticky (dashed) model is used. Competitors converge slower, especially in the
non-sticky case because non-adaptive methods are more sensitive to hyperparameters. Bottom: Segmentations
of 4 sequences by SVI, the Gibbs sampler, and our method under the non-sticky model (κ = 0). Top half shows
true state assignments; bottom shows aligned estimated states. Competitors are polluted by extra states (black).

the new batch statistics M ′
for states k > K. See the supplement for details on handling multiple sequences within a batch.

b and memoized statistics of other batches M ′

\b expanded by zeros

\b, S′

b, S′

The proposal for expanding ˆs′, ˆr′ with new states can ﬂexibly take any form, from very na¨ıve to very
data-driven. For data with “sticky” state persistence, we recommend randomly choosing one interval
[t, t + δ] of the current sequence to reassign when creating ˆs′, ˆr′, leaving other timesteps ﬁxed. We
split this interval into two contiguous blocks (one may be empty), each completely assigned to a
new state. In the supplement, we detail a linear-time search that ﬁnds the cut point that maximizes
the objective Ldata. Other proposals such as sub-cluster splits [11] could be easily incorporated in
our variational algorithm, but we ﬁnd this simple interval-based proposal to be fast and effective.

Merge proposals. Merge proposals try to ﬁnd a less redundant but equally expressive model. Each
proposal takes a pair of existing states i < j and constructs a candidate model where data from state
j is reassigned to state i. Conceptually this reassignment gives a new value ˆs′, but instead statistics
M ′, S′ can be directly computed and used in a global update for candidate parameters ˆτ ′, ˆρ′, ˆθ′.

i = Si + Sj, M ′
S′

:i = M:i + M:j, M ′

i: = Mi: + Mj:, M ′

ii = Mii + Mjj + Mji + Mij.

:i and row H ′

While most terms in L are linear functions of our cached sufﬁcient statistics, the entropy Lentropy
is not. Thus for each candidate merge pair (i, j), we use O(K) storage and computation to track
i: of the corresponding merged entropy matrix H ′. Because all terms in the
column H ′
H ′ matrix of Eq. (12) are non-negative, we can lower-bound Lentropy by summing a subset of H ′. As
detailed in the supplement, this allows us to rigorously bound the objective L′ for accepting multiple
merges of distinct state pairs. Because many entries of H ′ are near-zero, this bound is very tight,
and in practice enables us to scalably merge many redundant state pairs in each lap through the data.

To identify candidate merge pairs i, j, we examine all pairs of states and keep those that satisfy
data+L′
L′
hdp-local+L′
hdp-global > Ldata+Lhdp-local+Lhdp-global. Because entropy must decrease after any
merge (L′
entropy < Lentropy), this test is guaranteed to ﬁnd all possibly useful merges. It is much more
efﬁcient than the heuristic correlation score used in prior work on HDP topic models [14].

Deletes. Our proposal to delete a rarely-used state j begins by dropping row j and column j from
M to create M ′, and dropping Sj from S to create S′. Using a target dataset of sequences with
t=1 ˆrntj > 0.01}, we run global and local parameter
updates to reassign observations from former state j in a data-driven way. Rather than verifying on
only the target dataset as in [14], we accept or reject the delete proposal via the whole-dataset bound
L. To control computation, we only propose deleting states used in 10 or fewer sequences.

non-trivial mass on state j, x′ = {xn : PTn

6

stoch

memo

birth,del,merge

K=50

K=100

)
0
0
1
x
(
 
e
v
i
t
c
e
b
o

j

-3.4

-3.5

-3.6

1

10

100

100

75

50

25

K
 
s
e
t
a
t
s
 
m
u
n

0

)
c
e
s
(
 
e
m

i
t

1200

1000

800

600

400

200

0

p
u
d
e
e
p
s

64x
32x
16x
8x
4x
2x
1x

1 2 4 8 16 32 64

1 2 4 8 16 32 64

num pass thru data

num parallel workers
Figure 4: Segmentation of human epigenome: 15 million observations across 173 sequences (Sec. 5). Left:
Adaptive runs started at 1 state grow to 70 states within one lap and reach better L scores than 100-state non-
adaptive methods. Each run takes several days. Right: Wallclock times and speedup factors for a parallelized
local step on 1/3 of this dataset. 64 workers complete a local step with K = 50 states in under one minute.

num parallel workers

0.1

10 100
num pass thru data

1

5 Experiments

We compare our proposed birth-merge-delete memoized algorithm to memoized with delete and
merge moves only, and without any moves. We further run a blocked Gibbs sampler [6] that was
previously shown to mix faster than slice samplers [22], and our own implementation of SVI for
objective L. These baselines maintain a ﬁxed number of states K, though some states may have
usage fall to zero. We start all ﬁxed-K methods (including the sampler) from matched initializations.
See the supplement for futher discussion and all details needed to reproduce these experiments.

In Fig. 3, we study 32 toy data sequences generated from 8 Gaussian states with sticky
Toy data.
transitions [8]. From an abundant initialization with 50 states, the sampler and non-adaptive varia-
tional methods require hundreds of laps to remove redundant states, especially under a non-sticky
model (κ = 0). In contrast, our adaptive methods reach the ideal of zero Hamming distance within
a few dozen laps regardless of stickiness, suggesting less sensitivity to hyperparameters.

Speaker diarization. We study 21 unrelated audio recordings of meetings with an unknown num-
ber of speakers from the NIST 2007 speaker diarization challenge [23]. The sticky HDP-HMM
previously achieved state-of-the-art diarization performance [6] using a sampler that required hours
of computation. We ran methods from 10 matched initializations with 25 states and κ = 100, com-
puting Hamming distance on non-speech segments as in the standard DER metric. Fig. 5 shows that
within minutes, our algorithms consistently ﬁnd segmentations better aligned to true speaker labels.

Labelled N = 6 motion capture. Fox et al. [12] introduced a 6 sequence dataset with labels for
12 exercise types, illustrated in Fig. 1. Each sequence has 12 joint angles (wrist, knee, etc.) captured
at 0.1 second intervals. Fig. 6 shows that non-adaptive methods struggle even when initialized
abundantly with 30 (dashed lines) or 60 (solid) states, while our adaptive methods reach better
values of the objective L and cleaner many-to-one alignment to true exercises.

Large N = 124 motion capture. Next, we apply scalable methods to the 124 sequence dataset of
[12]. We lack ground truth here, but Fig. 7 shows deletes and merges making consistent reductions
from abundant initializations and births growing from K = 1. Fig. 7 also shows estimated segmen-
tations for 10 representative sequences, along with skeleton illustrations for the 10 most-used states
in this subset. These segmentations align well with held-out text descriptions.

Chromatin segmentation. Finally, we study segmenting the human genome by the appearance
patterns of regulatory proteins [24]. We observe 41 binary signals from [3] at 200bp intervals
throughout a white blood cell line (CD4T). Each binary value indicates the presence or absence
of an acetylation or methylation that controls gene expression. We divide the whole epigenome into
173 sequences (one per batch) with total size T = 15.4 million. Fig. 4 shows our method can grow
from 1 state to 70 states and compete favorably with non-adaptive competitors. We also demonstrate
that our parallelized local step leads to big 25x speedups in processing such large datasets.

6 Conclusion

Our new variational algorithms adapt HMM state spaces to ﬁnd clean segmentations driven by
Bayesian model selection. Relative to prior work [14], our contributions include a new bound for the
sticky HDP-HMM, births with guaranteed improvement, local step parallelization, and better merge
selection rules. Our multiprocessing-based Python code is targeted at genome-scale applications.
Acknowledgments This research supported in part by NSF CAREER Award No. IIS-1349774. M. Hughes
supported in part by an NSF Graduate Research Fellowship under Grant No. DGE0228243.

7

i

g
n
m
m
a
H
 
r
e
p
m
a
s

l

0.6

0.5

0.4

0.3

0.2

0.1

0.0

0.0 0.1 0.2 0.3 0.4 0.5 0.6
delete-merge Hamming

sampler

memo

delete,merge

birth,delete,merge

j

e
v
i
t
c
e
b
o
 
n
a
r
t

i

Meeting 11 (best)

Meeting 16 (avg.)

Meeting 21 (worst)

−2.50

−2.55

−2.60

−2.65

−2.70

−2.75

−2.80

1

10

100 1000
elapsed time (sec)

j

e
v
i
t
c
e
b
o
 
n
a
r
t

i

−2.55

−2.60

−2.65

−2.70

1

10

100 1000
elapsed time (sec)

j

e
v
i
t
c
e
b
o
 
n
a
r
t

i

−2.40

−2.45

−2.50

−2.55

1

10

100 1000
elapsed time (sec)

.
t
s
i
d
 
g
n
m
m
a
H

i

0.8

0.6

0.4

0.2

0.0

.
t
s
i
d
 
g
n
m
m
a
H

i

0.8

0.6

0.4

0.2

0.0

.
t
s
i
d
 
g
n
m
m
a
H

i

0.8

0.6

0.4

0.2

0.0

1

10

100 1000
elapsed time (sec)

100 1000
elapsed time (sec)
Figure 5: Method comparison on speaker diarization from common K = 25 initializations (Sec. 5). Left: Scat-
terplot of ﬁnal Hamming distance for our adaptive method and the sampler. Across 21 meetings (each with 10
initializations shown as individual dots) our method ﬁnds segmentations closer to ground truth. Right: Traces
of objective L and Hamming distance for meetings representative of good, average, and poor performance.

100 1000
elapsed time (sec)

10

10

1

1

j

e
v
i
t
c
e
b
o
 
n
a
r
t

i

−2.2

−2.4

−2.6

−2.8

1

10

100 1000
num pass thru data

60

40

20

K
 
s
e
t
a
t
s
 
m
u
n

0

1

10

100 1000
num pass thru data

.
t
s
i
d
 
g
n
m
m
a
H

i

0.8

0.6

0.4

0.2

0.0

stoch
sampler
memo
delete,merge
birth,delete,merge

1

10

100 1000
num pass thru data

birth: Hdist=0.34 K=28 @ 100 laps

del/merge: Hdist=0.30 K=13 @ 100 laps

sampler: Hdist=0.49 K=29 @ 1000 laps

0

50

100 150 200 250 300 350 400

0

50

100 150 200 250 300 350 400

0

50

100 150 200 250 300 350 400

Figure 6: Comparison on 6 motion capture streams (Sec. 5). Top: Our adaptive methods reach better L values
and lower distance from true exercise labels. Bottom: Segmentations from the best runs of birth/merge/delete
(left), only deletes and merges from 30 initial states (middle), and the sampler (right). Each sequence shows
true labels (top half) and estimates (bottom half) colored by the true state with highest overlap (many-to-one).

j

e
v
i
t
c
e
b
o
 
n
a
r
t

i

−2.4

−2.5

−2.6

200

150

100

50

K
 
s
e
t
a
t
s
 
m
u
n

1

10

100 1000
num pass thru data

0

1

10 100 1000
num pass thru data

1-1: playground jump  

1-2: playground climb  

1-3: playground climb 

2-7: swordplay 

5-3: dance 

5-4: dance 

5-5: dance 

6-3: basketball dribble 

6-4: basketball dribble 

6-5: basketball dribble 

!

"!

#!

$!

%!

&!!

Walk

Climb

Sword

Arms

Swing

Dribble

Jump

Balance

Ballet Leap

Ballet Pose

Figure 7: Study of 124 motion capture sequences (Sec. 5). Top Left: Objective L and state count K as more data
is seen. Solid lines have 200 initial states; dashed 100. Top Right: Final segmentation of 10 select sequences
by our method, with id numbers and descriptions from mocap.cs.cmu.edu. The 10 most used states are
shown in color, the rest with gray. Bottom: Time-lapse skeletons assigned to each highlighted state.

8

References

[1] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. Proc.

of the IEEE, 77(2):257–286, 1989.

[2] Zoubin Ghahramani. An introduction to hidden Markov models and Bayesian networks. International

Journal of Pattern Recognition and Machine Intelligence, 15(01):9–42, 2001.

[3] Jason Ernst and Manolis Kellis. Discovery and characterization of chromatin states for systematic anno-

tation of the human genome. Nature Biotechnology, 28(8):817–825, 2010.

[4] Matthew J. Beal, Zoubin Ghahramani, and Carl E. Rasmussen. The inﬁnite hidden Markov model. In

Neural Information Processing Systems, 2001.

[5] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the

American Statistical Association, 101(476):1566–1581, 2006.

[6] Emily B. Fox, Erik B. Sudderth, Michael I. Jordan, and Alan S. Willsky. A sticky HDP-HMM with

application to speaker diarization. Annals of Applied Statistics, 5(2A):1020–1056, 2011.

[7] Matthew J. Johnson and Alan S. Willsky. Stochastic variational inference for Bayesian time series models.

In International Conference on Machine Learning, 2014.

[8] Nicholas Foti, Jason Xu, Dillon Laird, and Emily Fox. Stochastic variational inference for hidden Markov

models. In Neural Information Processing Systems, 2014.

[9] Andreas Stolcke and Stephen Omohundro. Hidden Markov model induction by Bayesian model merging.

In Neural Information Processing Systems, 1993.

[10] Chong Wang and David M Blei. A split-merge MCMC algorithm for the hierarchical Dirichlet process.

arXiv preprint arXiv:1201.1657, 2012.

[11] Jason Chang and John W Fisher III. Parallel sampling of HDPs using sub-cluster splits.

In Neural

Information Processing Systems, 2014.

[12] Emily B. Fox, Michael C. Hughes, Erik B. Sudderth, and Michael I. Jordan. Joint modeling of multiple
time series via the beta process with application to motion capture segmentation. Annals of Applied
Statistics, 8(3):1281–1313, 2014.

[13] Michael C. Hughes and Erik B. Sudderth. Memoized online variational inference for Dirichlet process

mixture models. In Neural Information Processing Systems, 2013.

[14] Michael C. Hughes, Dae Il Kim, and Erik B. Sudderth. Reliable and scalable variational inference for the

hierarchical Dirichlet process. In Artiﬁcial Intelligence and Statistics, 2015.

[15] Yee Whye Teh, Kenichi Kurihara, and Max Welling. Collapsed variational inference for HDP. In Neural

Information Processing Systems, 2008.

[16] Michael Bryant and Erik B. Sudderth. Truly nonparametric online variational inference for hierarchical

Dirichlet processes. In Neural Information Processing Systems, 2012.

[17] Percy Liang, Slav Petrov, Michael I Jordan, and Dan Klein. The inﬁnite PCFG using hierarchical Dirichlet

processes. In Empirical Methods in Natural Language Processing, 2007.

[18] Matthew James Beal. Variational algorithms for approximate Bayesian inference. PhD thesis, University

of London, 2003.

[19] Matt Hoffman, David Blei, Chong Wang, and John Paisley. Stochastic variational inference. Journal of

Machine Learning Research, 14(1), 2013.

[20] Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C. Wilson, and Michael I. Jordan. Streaming

variational Bayes. In Neural Information Processing Systems, 2013.

[21] Chong Wang and David Blei. Truncation-free online variational inference for Bayesian nonparametric

models. In Neural Information Processing Systems, 2012.

[22] J. Van Gael, Y. Saatci, Y. W. Teh, and Z. Ghahramani. Beam sampling for the inﬁnite hidden Markov

model. In International Conference on Machine Learning, 2008.

[23] NIST. Rich transcriptions database. http://www.nist.gov/speech/tests/rt/, 2007.

[24] Michael M. Hoffman, Orion J. Buske, Jie Wang, Zhiping Weng, Jeff A. Bilmes, and William S. Noble.
Unsupervised pattern discovery in human chromatin structure through genomic segmentation. Nature
methods, 9(5):473–476, 2012.

9

